[
  {
    "objectID": "basics/index.html",
    "href": "basics/index.html",
    "title": "Scientific computing with Julia",
    "section": "",
    "text": "logo"
  },
  {
    "objectID": "basics/index.html#installation",
    "href": "basics/index.html#installation",
    "title": "Scientific computing with Julia",
    "section": "Installation",
    "text": "Installation\n\nDownload for your plaform at http://julialang.org/downloads/\nYou can also try online via https://www.juliabox.com/ which provides hosted Julia notebooks on Google Cloud.\nIf you need corporate support, https://juliacomputing.com/products/juliapro.html provides a batteries included installation of Julia. The company is run by some of the creators of the language and provides a single install with all of the most important add-ons.\nMost Linux distributions come with Julia packages in their repositories. However, these may lag somewhat behind the current rather fast development cycle.\nNotebooks are available on https://github.com/pnavaro/math-julia"
  },
  {
    "objectID": "basics/index.html#installing-julia-on-linux",
    "href": "basics/index.html#installing-julia-on-linux",
    "title": "Scientific computing with Julia",
    "section": "Installing Julia on Linux",
    "text": "Installing Julia on Linux\nDownload the tar archive from https://julialang.org/downloads and rename the directory like so:\ncd ~\ntar -xzf Downloads/julia-1.0.1-linux-x86_64.tar.gz \nYou may also want to add julia to your path\nexport PATH=$PATH:~/julia-1.0.1/bin\necho 'export PATH=$PATH:~/julia-1.0.1/bin' >>~/.bash_profile"
  },
  {
    "objectID": "basics/index.html#run-julia-code.",
    "href": "basics/index.html#run-julia-code.",
    "title": "Scientific computing with Julia",
    "section": "Run julia code.",
    "text": "Run julia code.\nJulia programs use “.jl” extension by convention and can be executed in the julia prompt with:\ninclude(\"my_program.jl\")\n\nJulia is first translated into an intermediate representation.\nThen LLVM compiles it for your machine.\n\nThis means that - re-running the same code is faster the second time around - it runs at speeds comparable to compiled C or Fortran code"
  },
  {
    "objectID": "basics/index.html#ide",
    "href": "basics/index.html#ide",
    "title": "Scientific computing with Julia",
    "section": "IDE",
    "text": "IDE\n\nJulia shell\nCommand line : julia my_program.jl\nJulia notebooks (Jupyter)\nNo dedicated IDE but plugins for existing tools.\nIntellJ, Eclipse, PyCharm\nVS Code\nAtom and Juno\nSublime Text 3\n\nI personally use Jupyter for development but Atom seems to be the most used environment."
  },
  {
    "objectID": "basics/index.html#packages",
    "href": "basics/index.html#packages",
    "title": "Scientific computing with Julia",
    "section": "Packages",
    "text": "Packages\n\nUse ] to switch to package manager.\n\npkg> add IJulia\nwill install the package. Type help to display all available commands.\nUse “backspace” to go back to the julia shell.\nhttps://pkg.julialang.org\nThe package is installed in directory ~/.julia/\nTo import the package, type:\nusing IJulia"
  },
  {
    "objectID": "basics/index.html#jupyter-notebook",
    "href": "basics/index.html#jupyter-notebook",
    "title": "Scientific computing with Julia",
    "section": "Jupyter notebook",
    "text": "Jupyter notebook\nThe Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\ntype:\nusing IJulia\nnotebook()  # use notebook(detached=true) \nTo convert a notebook file .ipynb in julia program .jl: * In the top menu File->Download as * Command line : ipython nbconvert --to script my_notebook.ipynb."
  },
  {
    "objectID": "basics/index.html#why-julia",
    "href": "basics/index.html#why-julia",
    "title": "Scientific computing with Julia",
    "section": "Why Julia?",
    "text": "Why Julia?\n\nIncrease the programmer productivity.\nPython is a very nice language to code a prototype but i had to use Cython to make it faster. And had to code in Fortran if the code had to be deployed on HPC cluster\nHigh-level languages like python and R let one explore and experiment rapidly, but can run slow.\nLow-level languages like Fortran/C++ tend to take longer to develop, but run fast.\nThis is sometimes called the “two language problem” and is something the Julia developers set out to eliminate.\nMy code runs much faster than Python, and typically similar to Fortran.\n\nJulia provides a “best of both worlds” experience for programmers who need to develop novel algorithms and bring them into production environments with minimal effort."
  },
  {
    "objectID": "basics/index.html#julia-features",
    "href": "basics/index.html#julia-features",
    "title": "Scientific computing with Julia",
    "section": "Julia features",
    "text": "Julia features\n\nHigh-level language for numerical computing.\nBorn in 2009 and version 1.0 was released in August 2018.\nDynamically-typed with optional types, feels like a scripting language, and has good support for interactive use.\nEasy to learn for people that comes from R and Python.\nDesigned from the beginning to be fast as Fortran and C\nJulia programs compile to efficient native code via LLVM.\nDesigned for parallelism, and provides built-in primitives for parallel computing\ncan call C and Fortran libraries natively\ncan call Python libraries via PyCall package\ncan call R functions via RCall package"
  },
  {
    "objectID": "basics/index.html#julia-is-a-language-made-for-science.",
    "href": "basics/index.html#julia-is-a-language-made-for-science.",
    "title": "Scientific computing with Julia",
    "section": "Julia is a language made for Science.",
    "text": "Julia is a language made for Science.\nhttp://www.stochasticlifestyle.com/some-state-of-the-art-packages-in-julia-v1-0\nMathematics * JuliaDiff – Differentiation tools * JuliaDiffEq – Differential equation solving and analysis * JuliaGeometry – Computational Geometry * JuliaGraphs – Graph Theory and Implementation * JuliaIntervals - Rigorous numerics with interval arithmetic & applications * JuliaMath – Mathematics made easy in Julia * JuliaOpt – Optimization (Gitter) * JuliaPolyhedra – Polyhedral computation * JuliaSparse – Sparse matrix solvers\nData Science * JuliaML – Machine Learning * JuliaStats – Statistics * JuliaImages – Image Processing * JuliaText – Natural Language Processing (NLP), Computational Linguistics and (textual) Information Retrieval * JuliaDatabases – Various database drivers for Julia * JuliaData – Data manipulation, storage, and I/O in Julia"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Scientific computing with Julia",
    "section": "",
    "text": "Introduction to Julia language"
  },
  {
    "objectID": "performance/01-put-code-inside-function.html",
    "href": "performance/01-put-code-inside-function.html",
    "title": "Performance critical code should be inside a function",
    "section": "",
    "text": "Let’s compute \\(y = a * x\\)\n\nn = 100_000\na = 1.2\nx = rand(Float64, n)\ny = rand(Float64, n)\n\n@time for i in eachindex(y, x)\n    y[i] += a * x[i]\nend\n\n\nTo optimize the code, Julia needs it to be inside a function.\n\nfunction axpy!(y, a, x)\n    for i in eachindex(y, x)\n        y[i] += a * x[i]\n    end\nend\n\n# warmup\naxpy!(y, a, x)\n\n# timing\n@time axpy!(y, a, x)"
  },
  {
    "objectID": "performance/02-avoid-untyped-global-variable.html",
    "href": "performance/02-avoid-untyped-global-variable.html",
    "title": "Avoid untyped global variables",
    "section": "",
    "text": "using BenchmarkTools\n\nvariable = 10 \n\nfunction add_using_global_variable(x)\n    return x + variable\nend\n\n@btime add_using_global_variable(10);"
  },
  {
    "objectID": "performance/02-avoid-untyped-global-variable.html#pass-the-variable-in-the-arguments-of-the-function",
    "href": "performance/02-avoid-untyped-global-variable.html#pass-the-variable-in-the-arguments-of-the-function",
    "title": "Avoid untyped global variables",
    "section": "Pass the variable in the arguments of the function",
    "text": "Pass the variable in the arguments of the function\n\nfunction add_using_function_arg(x, y)\n    return x + y\nend\n\n@btime add_using_function_arg(10, $variable);\n\n\n\n@code_llvm add_using_function_arg(10, variable)\n\n\n\n@code_llvm add_using_global_variable(10)"
  },
  {
    "objectID": "performance/02-avoid-untyped-global-variable.html#set-type-of-the-global-variable",
    "href": "performance/02-avoid-untyped-global-variable.html#set-type-of-the-global-variable",
    "title": "Avoid untyped global variables",
    "section": "Set type of the global variable",
    "text": "Set type of the global variable\n\nvariable_typed::Int = 10\n\nfunction add_using_global_variable_typed(x)\n    return x + variable_typed\nend\n\n@btime add_using_global_variable_typed(10);"
  },
  {
    "objectID": "performance/02-avoid-untyped-global-variable.html#use-the-keyword-const",
    "href": "performance/02-avoid-untyped-global-variable.html#use-the-keyword-const",
    "title": "Avoid untyped global variables",
    "section": "Use the keyword const",
    "text": "Use the keyword const\n\nconst constant = 10\n\nfunction add_by_passing_global_constant(x, v)\n    return x + v\nend\n\n@btime add_by_passing_global_constant(10, $constant);\n\n\n\nvariable = 10\n\nfunction sum_variable_many_times(n)\n    total = rand(variable)\n    for i in 1:n\n        total .+= rand(variable)\n    end\n    return total\nend\n\n@btime sum_variable_many_times(100);\n\n\n\nconst constant = 10\n\nfunction sum_constant_many_times(n)\n    total = rand(constant)\n    for i in 1:n\n        total .+= rand(constant)\n    end\n    return total\nend\n\n@btime sum_constant_many_times(100);"
  },
  {
    "objectID": "performance/03-pay-attention-to-memory-allocation.html",
    "href": "performance/03-pay-attention-to-memory-allocation.html",
    "title": "Pay attention to memory allocation",
    "section": "",
    "text": "function build_preallocate(n::Int)\n    @assert n >= 2\n    v = zeros(Int64,n)\n    v[1] = 1\n    v[2] = 1\n    for i = 3:n\n        v[i] = v[i-1] + v[i-2]\n    end\n    return v\nend\n\n\n\nfunction build_no_allocation(n::Int)\n    @assert n >= 2\n    v = Vector{Int64}()\n    push!(v,1)\n    push!(v,1)\n    for i = 3:n\n        push!(v,v[i-1]+v[i-2])\n    end\n    return v\nend"
  },
  {
    "objectID": "performance/03-pay-attention-to-memory-allocation.html#whenever-possible-preallocate-memory",
    "href": "performance/03-pay-attention-to-memory-allocation.html#whenever-possible-preallocate-memory",
    "title": "Pay attention to memory allocation",
    "section": "Whenever possible, preallocate memory",
    "text": "Whenever possible, preallocate memory\n\nisequal(build_preallocate(10),build_no_allocation(10))\n\n\nusing BenchmarkTools\n\nn = 100\n\n@btime build_no_allocation(n);\n\n@btime build_preallocate(n);\n\n\njulia --check-bounds=no -O3 --track-allocation=user build_no_allocation.jl\n\ncat build_no_allocation.jl.*.mem\n\n   - function build_no_allocation(n::Int)\n   0     @assert n >= 2\n  64     v = Vector{Int64}()\n  80     push!(v,1)\n   0     push!(v,1)\n   0     for i = 3:n\n1824         push!(v,v[i-1]+v[i-2])\n   0     end\n   0     return v\n   - end\n\njulia --check-bounds=no -O3 --track-allocation=user build_preallocate.jl\n\ncat build_preallocate.jl.*.mem\n\n  - function build_preallocate(n::Int)\n  0     @assert n >= 2\n896     v = zeros(Int64,n)\n  0     v[1] = 1\n  0     v[2] = 1\n  0     for i = 3:n\n  0         v[i] = v[i-1] + v[i-2]\n  0     end\n  0     return v\n  - end"
  },
  {
    "objectID": "performance/04-avoid-containers-with-abstract-type.html",
    "href": "performance/04-avoid-containers-with-abstract-type.html",
    "title": "Avoid containers with abstract type parameters",
    "section": "",
    "text": "a = Real[]\n\npush!(a, 1); push!(a, 2.0); push!(a, π)\n\nSince Real objects can be of arbitrary size and structure, a must be represented as an array of pointers to individually allocated Real objects. With concrete type Float64, b is stored as a contiguous block of 64-bit floating-point values that can be manipulated efficiently.\n\nb = Float64[]\n\npush!(b, 1); push!(b, 2.0); push!(b,  π)"
  },
  {
    "objectID": "performance/05-avoid-struct-fields-with-abstract-type.html",
    "href": "performance/05-avoid-struct-fields-with-abstract-type.html",
    "title": "Avoid struct fields with abstract type",
    "section": "",
    "text": "struct Cube\n    length\n    width\n    height\nend\n\nstruct CubeTyped\n    length::Float64\n    width::Float64\n    height::Float64\nend\n\nstruct CubeParametricTyped{T <: Real}\n    length::T\n    width::T\n    height::T\nend\n\n\n\nvolume(c) = c.length*c.width*c.height\n\nc1 = Cube(1.1,1.2,1.3)\nc2 = CubeTyped(1.1,1.2,1.3)\nc3 = CubeParametricTyped(1.1,1.2,1.3)\n@show volume(c1) == volume(c2) == volume(c3)\n\n\nusing BenchmarkTools\n@btime volume($c1) # not typed\n@btime volume($c2) # typed float\n@btime volume($c3) # typed parametric\n\n\n\n@code_warntype volume(c1)\n\n\n\n@code_warntype volume(c2)\n\n\n\n@code_warntype volume(c3)"
  },
  {
    "objectID": "performance/06-break-functions-into-multiple-definitions.html",
    "href": "performance/06-break-functions-into-multiple-definitions.html",
    "title": "Break functions into multiple definitions",
    "section": "",
    "text": "using LinearAlgebra\n\nfunction mynorm(A)\n    if isa(A, Vector)\n        return sqrt(real(dot(A,A)))\n    elseif isa(A, Matrix)\n        return maximum(svdvals(A))\n    else\n        error(\"mynorm: invalid argument\")\n    end\nend\nThis can be written more concisely and efficiently as:\nnorm(x::Vector) = sqrt(real(dot(x, x)))\n\nnorm(A::Matrix) = maximum(svdvals(A))"
  },
  {
    "objectID": "performance/07-write-type-stable-functions.html",
    "href": "performance/07-write-type-stable-functions.html",
    "title": "Write “type-stable” functions",
    "section": "",
    "text": "function square_plus_one(v::T) where T <:Number\n    g = v * v\n    return g + 1\nend\n\n\nv = rand()\n\n\n@code_warntype square_plus_one(v)\n\n\n\nw = 5\n\n\n@code_warntype square_plus_one(w)\n\n\n\nGreat! In the above two examples, we were able to predict what the output will be. This is because:\n\nfunction square_plus_one(v::T) where T <:Number\n    g = v*v         # Type(T * T) ==> T\n    return g+1      # Type(T + Int)) ==> \"max\" (T,Int)\nend\n\n\nNote that in both calls the return type was different, once Float64 and once Int64. But the function is still type stable.\n\n\n\nfunction zero_or_val(x::Real)\n    if x >= 0\n        return x\n    else\n        return 0\n    end\nend\n@code_warntype zero_or_val(0.2)\n\n\n\nYou can avoid type instable code by using the promote_type function which returns the highest of the two types passed.\n\n\nfunction zero_or_val_stable(x::Real)\n    if x >= 0\n        y = x\n    else\n        y = 0\n    end\n    T = promote_type(typeof(x),Int)\n    return T(y)\nend\n@code_warntype zero_or_val_stable(0.2)"
  },
  {
    "objectID": "performance/08-avoid-changing-the-type-of-a-variable.html",
    "href": "performance/08-avoid-changing-the-type-of-a-variable.html",
    "title": "Avoid changing the type of a variable",
    "section": "",
    "text": "Let us say we want to play the following game, I give you a vector of numbers. And you want to accumulate the sum as follows. For each number in the vector, you toss a coin (rand()), if it is heads (>=0.5), you add 1. Otherwise, you add the number itself.\n\nfunction flipcoin_then_add(v::Vector{T}) where T <: Real\n    s = 0\n    for vi in v\n        r = rand()\n        if r >=0.5\n            s += 1\n        else\n            s += vi\n        end\n    end\nend\n\n\n\nfunction flipcoin_then_add_typed(v::Vector{T}) where T <: Real\n    s = zero(T)\n    for vi in v\n        r = rand()\n        if r >=0.5\n            s += one(T)\n        else\n            s += vi\n        end\n    end\nend\n\n\n\nusing BenchmarkTools\n\nmyvec = rand(1000)\n@show flipcoin_then_add(myvec) == flipcoin_then_add_typed(myvec)\n\n\n@btime flipcoin_then_add(rand(1000))\n@btime flipcoin_then_add_typed(rand(1000))"
  },
  {
    "objectID": "performance/09-access-arrays-in-memory-order.html",
    "href": "performance/09-access-arrays-in-memory-order.html",
    "title": "Access arrays in memory order, along columns",
    "section": "",
    "text": "function compute_dist!(x, dist)\n    for i=eachindex(x)\n        for j=eachindex(x)\n            dist[i, j] = abs(x[i] - x[j])\n        end\n    end\nend\n\nN = 10_000\nx = rand(Float64, N)\ndist = Array{Float64}(undef, (N, N))\n\ncompute_dist!(x, dist)\n@time compute_dist!(x, dist)\n\n\n\nfunction compute_dist!(x, dist)\n    for j=eachindex(x)\n        for i=eachindex(x)\n            dist[i, j] = abs(x[i] - x[j])\n        end\n    end\nend\n\nN = 10_000\nx = rand(Float64, N)\ndist = Array{Float64}(undef, (N, N))\n\ncompute_dist!(x, dist)\n@time compute_dist!(x, dist)\n\n\n\nusing BenchmarkTools, FFTW\nxmin, xmax, nx = 0, 4π, 1024\nymin, ymax, ny = 0, 4π, 1024\nx = LinRange(xmin, xmax, nx+1)[1:end-1]\ny = LinRange(ymin, ymax, ny+1)[1:end-1]\n\nfunction df_dy!( f )\n    ky  = 2π ./ (ymax-ymin) .* fftfreq(ny, ny)\n    exky = exp.( 1im .* ky' .* x)\n    f .= real(ifft(exky .* fft(f, 2), 2))\nend\n\nf1 = sin.(x) .* cos.(y') \ndf_dy!( f1 )\n\n\n\nfunction df_dy_transposed!( f )\n    ft = transpose(f)\n    ky  = 2π ./ (ymax-ymin) .* fftfreq(ny, ny)\n    exky = exp.( 1im .* ky .* x')\n    f .= transpose(real(ifft(exky .* fft(ft, 1), 1)))\nend\nf2 = sin.(x) .* cos.(y') \ndf_dy_transposed!( f2 )\n\n\n\nisequal(f1, f2)\n\n\nf = sin.(x) .* cos.(y')\n@btime df_dy!($f);\nf = sin.(x) .* cos.(y')\n@btime df_dy_transposed!($f);"
  },
  {
    "objectID": "performance/10-preallocating-outputs.html",
    "href": "performance/10-preallocating-outputs.html",
    "title": "Pre-allocating outputs",
    "section": "",
    "text": "You have a vector b and a vector h where b[i] is the base length of triangle i and h[i] is the height length. The experiment is to find the hypotenuse value of all triangles.\n\n\nusing BenchmarkTools\n\nb = rand(1000)*10\nh = rand(1000)*10\nfunction find_hypotenuse(b::Vector{T},h::Vector{T}) where T <: Real\n    return sqrt.(b.^2+h.^2)\nend\n\n\n@btime find_hypotenuse($b, $h);\n\n\n\nfunction find_hypotenuse_optimized(b::Vector{T},h::Vector{T}) where T <: Real\n    accum_vec = similar(b)\n    for i = eachindex(accum_vec)\n        accum_vec[i] = b[i]^2\n        accum_vec[i] += h[i]^2 # here, we used the same space in memory to hold the sum\n        accum_vec[i] = sqrt(accum_vec[i]) # same thing here, to hold the sqrt\n    end\n    return accum_vec\nend\n\n\n@btime find_hypotenuse_optimized($b, $h);\n\n\n\nusing FFTW, LinearAlgebra\n\nxmin, xmax, nx = 0, 4π, 1024\nymin, ymax, ny = 0, 4π, 1024\n\nx = LinRange(xmin, xmax, nx+1)[1:end-1]\ny = LinRange(ymin, ymax, ny+1)[1:end-1]\nky  = 2π ./ (ymax-ymin) .* fftfreq(ny, ny)\nexky = exp.( 1im .* ky .* x')\n\nf  = zeros(ComplexF64, (nx,ny))\nfᵗ = zeros(ComplexF64, reverse(size(f)))\nf̂ᵗ = zeros(ComplexF64, reverse(size(f)))\nf .= sin.(x) .* cos.(y')\n\nplan = plan_fft(fᵗ, 1, flags=FFTW.PATIENT)\n\n\n\nfunction df_dy_optimized!( f, fᵗ, f̂ᵗ, plan, exky )\n\n    transpose!(fᵗ,f)\n    mul!(f̂ᵗ,  plan, fᵗ)\n    f̂ᵗ .= f̂ᵗ .* exky\n    ldiv!(fᵗ, plan, f̂ᵗ)\n    transpose!(f, fᵗ)\n\nend\n\n@btime df_dy_optimized!($f, $fᵗ, $f̂ᵗ, $plan, $exky );"
  },
  {
    "objectID": "performance/11-fused-vectorized-operations.html",
    "href": "performance/11-fused-vectorized-operations.html",
    "title": "Fuse vectorized operations",
    "section": "",
    "text": "f(x) = 3x.^2 + 4x + 7x.^3;\n\nfdot(x) = @. 3x^2 + 4x + 7x^3; # = 3 .* x.^2 .+ 4 .* x .+ 7 .* x.^3\n\nBoth f and fdot compute the same thing.\n\nx = rand(10^6);\nf(x) # warmup\n@time f(x);\n\n\nfdot(x) # warmup\n@time fdot(x);\n\n\nf.(x) # warmup\n@time f.(x);\n\n\nfdot(x) is faster and allocates less memory, because each * and + operation in f(x) allocates a new temporary array and executes in a separate loop."
  },
  {
    "objectID": "performance/12-consider-using-views-for-slices.html",
    "href": "performance/12-consider-using-views-for-slices.html",
    "title": "Consider using views for slices",
    "section": "",
    "text": "const N = 50_000_000\nconst a = 1.2\nconst x = rand(Float64, N)\nconst y = rand(Float64, N)\n\nconst nn = 100\nconst n_start = 1 + nn\nconst n_end = N - nn\n\n# warmup\n@. y[n_start:n_end] += a * x[n_start:n_end]\n\n# timing\n@time @. y[n_start:n_end] += a * x[n_start:n_end];\n\n\n# warmup\n@. @views y[n_start:n_end] += a * x[n_start:n_end]\n\n# timing\n@time @. @views y[n_start:n_end] += a * x[n_start:n_end];"
  },
  {
    "objectID": "performance/13-copy-irregularly-accessed-data.html",
    "href": "performance/13-copy-irregularly-accessed-data.html",
    "title": "Copy irregularly-accessed data into a contiguous array before operating on it",
    "section": "",
    "text": "using Random\n\nx = randn(1_000_000);\n\ninds = shuffle(1:1_000_000)[1:800000];\n\nA = randn(50, 1_000_000);\n\nxtmp = zeros(800_000);\n\nAtmp = zeros(50, 800_000);\n\n@time sum(view(A, :, inds) * view(x, inds))\n@time sum(view(A, :, inds) * view(x, inds))\n\n\nIrregular access patterns and non-contiguous views can drastically slow down computations on arrays because of non-sequential memory access. Copying the views into plain arrays speeds up the multiplication even with the cost of the copying operation.\n\n\n\n@time begin\n    copyto!(xtmp, view(x, inds))\n    copyto!(Atmp, view(A, :, inds))\n    sum(Atmp * xtmp)\nend\n\n\n@time begin\n    copyto!(xtmp, view(x, inds))\n    copyto!(Atmp, view(A, :, inds))\n    sum(Atmp * xtmp)\nend"
  },
  {
    "objectID": "performance/14-consider-static-arrays.html",
    "href": "performance/14-consider-static-arrays.html",
    "title": "Consider StaticArrays.jl for small fixed-size vector/matrix operations",
    "section": "",
    "text": "using DifferentialEquations, BenchmarkTools\n\n\n\nfunction lorenz(u,p,t)\n dx = 10.0*(u[2]-u[1])\n dy = u[1]*(28.0-u[3]) - u[2]\n dz = u[1]*u[2] - (8/3)*u[3]\n [dx,dy,dz]\nend\n\n\nu0 = [1.0;0.0;0.0]\ntspan = (0.0,100.0)\nprob = ODEProblem(lorenz,u0,tspan)\n@benchmark solve(prob,Tsit5())\n\n\n\nfunction lorenz!(du,u,p,t)\n du[1] = 10.0*(u[2]-u[1])\n du[2] = u[1]*(28.0-u[3]) - u[2]\n du[3] = u[1]*u[2] - (8/3)*u[3]\nend\n\n\nu0 = [1.0;0.0;0.0]\ntspan = (0.0,100.0)\nprob = ODEProblem(lorenz!,u0,tspan)\n@benchmark solve(prob,Tsit5())\n\n\n\nStaticArray is statically-sized (known at compile time) and thus its accesses are quick. Additionally, the exact block of memory is known in advance by the compiler, and thus re-using the memory is cheap. This means that allocating on the stack has essentially no cost!\n\n\nusing StaticArrays\n\nfunction lorenz_static(u,p,t)\n dx = 10.0*(u[2]-u[1])\n dy = u[1]*(28.0-u[3]) - u[2]\n dz = u[1]*u[2] - (8/3)*u[3]\n @SVector [dx,dy,dz]\nend\n\n\nu0 = @SVector [1.0,0.0,0.0]\ntspan = (0.0,100.0)\nprob = ODEProblem(lorenz_static,u0,tspan)\n@benchmark solve(prob,Tsit5())"
  },
  {
    "objectID": "performance/15-avoid-string-interpolation-for-io.html",
    "href": "performance/15-avoid-string-interpolation-for-io.html",
    "title": "Avoid string interpolation for I/O",
    "section": "",
    "text": "When writing data to a file (or other I/O device), forming extra intermediate strings is a source of overhead. Instead of:\n\nprintln(file, \"$a $b\")\nuse:\nprintln(file, a, \" \", b)"
  },
  {
    "objectID": "performance/16-performance-annotations.html",
    "href": "performance/16-performance-annotations.html",
    "title": "Performance Annotations: @fastmath @inbounds @simd",
    "section": "",
    "text": "function new_sum(myvec::Vector{Int})\n    s = zero(eltype(myvec))\n    for i = eachindex(myvec)\n        s += myvec[i]\n    end\n    return s\nend\n\nfunction new_sum_inbounds(myvec::Vector{Int})\n    s = zero(eltype(myvec))\n    @inbounds for i = eachindex(myvec)\n        s += myvec[i]\n    end\n    return s\nend\n\n\nusing BenchmarkTools\n\nmyvec = collect(1:1000000)\n@btime new_sum($myvec)\n@btime new_sum_inbounds($myvec)\n\n\n\n\n\n@noinline function inner(x, y)\n    s = zero(eltype(x))\n    for i = eachindex(x, y)\n        @inbounds s += x[i]*y[i]\n    end\n    return s\nend;\n\n\n\n@noinline function innersimd(x, y)\n    s = zero(eltype(x))\n    @simd for i = eachindex(x, y)\n        @inbounds s += x[i] * y[i]\n    end\n    return s\nend;\n\n\n\n\n\nfunction timeit(n, reps)\n    x = rand(Float32, n)\n    y = rand(Float32, n)\n    s = zero(Float64)\n    time = @elapsed for j in 1:reps\n        s += inner(x, y)\n    end\n    println(\"GFlop/sec        = \", 2n*reps / time*1E-9)\n    time = @elapsed for j in 1:reps\n        s += innersimd(x, y)\n    end\n    println(\"GFlop/sec (SIMD) = \", 2n*reps / time*1E-9)\nend\ntimeit(10, 10)\ntimeit(1000, 1000)\n\n\n\nfunction init!(u::Vector)\n    n = length(u)\n    dx = 1.0 / (n-1)\n    @fastmath @inbounds @simd for i in eachindex(u) \n        u[i] = sin(2pi*dx*i)\n    end\nend\n\nfunction deriv!(u::Vector, du)\n    n = length(u)\n    dx = 1.0 / (n-1)\n    @fastmath @inbounds du[1] = (u[2] - u[1]) / dx\n    @fastmath @inbounds @simd for i in 2:n-1\n        du[i] = (u[i+1] - u[i-1]) / (2*dx)\n    end\n    @fastmath @inbounds du[n] = (u[n] - u[n-1]) / dx\nend\n\n\n\nfunction mynorm(u::Vector)\n    T = eltype(u)\n    s = zero(T)\n    @fastmath @inbounds @simd for i in eachindex(u)\n        s += u[i]^2\n    end\n    @fastmath @inbounds return sqrt(s)\nend\n\n\n\nfunction main(n)\n    u = Vector{Float64}(undef, n)\n    init!(u)\n    du = similar(u)\n\n    deriv!(u, du)\n    nu = mynorm(du)\n\n    @time for i in 1:10^6\n        deriv!(u, du)\n        nu = mynorm(du)\n    end\n\n    println(\" nu = $nu \")\nend\n\nmain(10)\n@time main(2000)\n\n\n\nrun(`julia --math-mode=ieee wave.jl`)"
  },
  {
    "objectID": "performance/index.html",
    "href": "performance/index.html",
    "title": "Scientific computing with Julia",
    "section": "",
    "text": "Julia Docs https://docs.julialang.org/en/v1/manual/performance-tips/\nBenoît Fabrèges https://plmlab.math.cnrs.fr/fabreges/julia-2019/\nNassar Huda https://github.com/nassarhuda/JuliaTutorials\nTom Kwong https://github.com/PacktPublishing/Hands-on-Design-Patterns-and-Best-Practices-with-Julia/"
  }
]