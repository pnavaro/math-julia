[
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Julia Docs\nJulia for high-performance scientific computing\nIntroduction to Julia for Scientific Computing and Data Science\nBenoît Fabrèges\nNassar Huda\nTom Kwong"
  },
  {
    "objectID": "performance/when-avoid-abstract-type.html",
    "href": "performance/when-avoid-abstract-type.html",
    "title": "Abstract type",
    "section": "",
    "text": "a = Real[]\n\npush!(a, 1); push!(a, 2.0); push!(a, π)\n\n3-element Vector{Real}:\n 1\n 2.0\n π = 3.1415926535897...\n\n\nSince Real objects can be of arbitrary size and structure, a must be represented as an array of pointers to individually allocated Real objects. With concrete type Float64, b is stored as a contiguous block of 64-bit floating-point values that can be manipulated efficiently.\n\nb = Float64[]\n\npush!(b, 1); push!(b, 2.0); push!(b,  π)\n\n3-element Vector{Float64}:\n 1.0\n 2.0\n 3.141592653589793"
  },
  {
    "objectID": "performance/when-avoid-abstract-type.html#avoid-containers-with-abstract-type-parameters",
    "href": "performance/when-avoid-abstract-type.html#avoid-containers-with-abstract-type-parameters",
    "title": "Abstract type",
    "section": "",
    "text": "a = Real[]\n\npush!(a, 1); push!(a, 2.0); push!(a, π)\n\n3-element Vector{Real}:\n 1\n 2.0\n π = 3.1415926535897...\n\n\nSince Real objects can be of arbitrary size and structure, a must be represented as an array of pointers to individually allocated Real objects. With concrete type Float64, b is stored as a contiguous block of 64-bit floating-point values that can be manipulated efficiently.\n\nb = Float64[]\n\npush!(b, 1); push!(b, 2.0); push!(b,  π)\n\n3-element Vector{Float64}:\n 1.0\n 2.0\n 3.141592653589793"
  },
  {
    "objectID": "performance/when-avoid-abstract-type.html#avoid-struct-fields-with-abstract-type",
    "href": "performance/when-avoid-abstract-type.html#avoid-struct-fields-with-abstract-type",
    "title": "Abstract type",
    "section": "Avoid struct fields with abstract type",
    "text": "Avoid struct fields with abstract type\nTypes matter, when you know anything about the types of your variables, include them in your code to make it run faster\n\nstruct Cube\n    length\n    width\n    height\nend\n\nstruct CubeTyped\n    length::Float64\n    width::Float64\n    height::Float64\nend\n\nstruct CubeParametricTyped{T &lt;: Real}\n    length::T\n    width::T\n    height::T\nend\n\n\n\nvolume(c) = c.length*c.width*c.height\n\nc1 = Cube(1.1,1.2,1.3)\nc2 = CubeTyped(1.1,1.2,1.3)\nc3 = CubeParametricTyped(1.1,1.2,1.3)\n@show volume(c1) == volume(c2) == volume(c3)\n\nvolume(c1) == volume(c2) == volume(c3) = true\n\n\ntrue\n\n\n\nusing BenchmarkTools\n@btime volume($c1) # not typed\n@btime volume($c2) # typed float\n@btime volume($c3) # typed parametric\n\n  18.228 ns (1 allocation: 16 bytes)\n  2.785 ns (0 allocations: 0 bytes)\n  2.785 ns (0 allocations: 0 bytes)\n\n\n1.7160000000000002\n\n\n\n\n@code_warntype volume(c1)\n\nMethodInstance for volume(::Cube)\n  from volume(c) @ Main In[5]:1\nArguments\n  #self#::Core.Const(volume)\n  c::Cube\nBody::Any\n1 ─ %1 = Base.getproperty(c, :length)::Any\n│   %2 = Base.getproperty(c, :width)::Any\n│   %3 = Base.getproperty(c, :height)::Any\n│   %4 = (%1 * %2 * %3)::Any\n└──      return %4\n\n\n\n\n\n@code_warntype volume(c2)\n\nMethodInstance for volume(::CubeTyped)\n  from volume(c) @ Main In[5]:1\nArguments\n  #self#::Core.Const(volume)\n  c::CubeTyped\nBody::Float64\n1 ─ %1 = Base.getproperty(c, :length)::Float64\n│   %2 = Base.getproperty(c, :width)::Float64\n│   %3 = Base.getproperty(c, :height)::Float64\n│   %4 = (%1 * %2 * %3)::Float64\n└──      return %4\n\n\n\n\n\n@code_warntype volume(c3)\n\nMethodInstance for volume(::CubeParametricTyped{Float64})\n  from volume(c) @ Main In[5]:1\nArguments\n  #self#::Core.Const(volume)\n  c::CubeParametricTyped{Float64}\nBody::Float64\n1 ─ %1 = Base.getproperty(c, :length)::Float64\n│   %2 = Base.getproperty(c, :width)::Float64\n│   %3 = Base.getproperty(c, :height)::Float64\n│   %4 = (%1 * %2 * %3)::Float64\n└──      return %4"
  },
  {
    "objectID": "performance/put-code-inside-function.html",
    "href": "performance/put-code-inside-function.html",
    "title": "Put code inside functions",
    "section": "",
    "text": "Performance critical code should be inside a function\nLet’s compute \\(y = a * x\\)\nn = 100_000\na = 1.2\nx = rand(Float64, n)\ny = rand(Float64, n)\n\n@time for i in eachindex(y, x)\n    y[i] += a * x[i]\nend\n\n  0.046773 seconds (699.26 k allocations: 12.205 MiB, 39.14% gc time, 33.41% compilation time)\nTo optimize the code, Julia needs it to be inside a function.\nfunction axpy!(y, a, x)\n    for i in eachindex(y, x)\n        y[i] += a * x[i]\n    end\nend\n\n# warmup\naxpy!(y, a, x)\n\n# timing\n@time axpy!(y, a, x)\n\n  0.000037 seconds"
  },
  {
    "objectID": "performance/put-code-inside-function.html#avoid-untyped-global-variables",
    "href": "performance/put-code-inside-function.html#avoid-untyped-global-variables",
    "title": "Put code inside functions",
    "section": "Avoid untyped global variables",
    "text": "Avoid untyped global variables\n\nUsing global variable\n\nusing BenchmarkTools\n\nvariable = 10 \n\nfunction add_using_global_variable(x)\n    return x + variable\nend\n\n@btime add_using_global_variable(10);\n\n  19.122 ns (0 allocations: 0 bytes)\n\n\n\n\nPass the variable in the arguments of the function\n\nfunction add_using_function_arg(x, y)\n    return x + y\nend\n\n@btime add_using_function_arg(10, $variable);\n\n  2.785 ns (0 allocations: 0 bytes)\n\n\n\n\n@code_llvm add_using_function_arg(10, variable)\n\n;  @ In[5]:1 within `add_using_function_arg`\ndefine i64 @julia_add_using_function_arg_989(i64 signext %0, i64 signext %1) #0 {\ntop:\n;  @ In[5]:2 within `add_using_function_arg`\n; ┌ @ int.jl:87 within `+`\n   %2 = add i64 %1, %0\n; └\n  ret i64 %2\n}\n\n\n\n\n@code_llvm add_using_global_variable(10)\n\n;  @ In[4]:5 within `add_using_global_variable`\ndefine nonnull {}* @julia_add_using_global_variable_1012(i64 signext %0) #0 {\ntop:\n  %1 = alloca [2 x {}*], align 8\n  %gcframe2 = alloca [4 x {}*], align 16\n  %gcframe2.sub = getelementptr inbounds [4 x {}*], [4 x {}*]* %gcframe2, i64 0, i64 0\n  %.sub = getelementptr inbounds [2 x {}*], [2 x {}*]* %1, i64 0, i64 0\n  %2 = bitcast [4 x {}*]* %gcframe2 to i8*\n  call void @llvm.memset.p0i8.i32(i8* noundef nonnull align 16 dereferenceable(32) %2, i8 0, i32 32, i1 false)\n  %thread_ptr = call i8* asm \"movq %fs:0, $0\", \"=r\"() #4\n  %ppgcstack_i8 = getelementptr i8, i8* %thread_ptr, i64 -8\n  %ppgcstack = bitcast i8* %ppgcstack_i8 to {}****\n  %pgcstack = load {}***, {}**** %ppgcstack, align 8\n;  @ In[4]:6 within `add_using_global_variable`\n  %3 = bitcast [4 x {}*]* %gcframe2 to i64*\n  store i64 8, i64* %3, align 16\n  %4 = getelementptr inbounds [4 x {}*], [4 x {}*]* %gcframe2, i64 0, i64 1\n  %5 = bitcast {}** %4 to {}***\n  %6 = load {}**, {}*** %pgcstack, align 8\n  store {}** %6, {}*** %5, align 8\n  %7 = bitcast {}*** %pgcstack to {}***\n  store {}** %gcframe2.sub, {}*** %7, align 8\n  %8 = load atomic {}*, {}** inttoptr (i64 139778578188376 to {}**) unordered, align 8\n  %9 = getelementptr inbounds [4 x {}*], [4 x {}*]* %gcframe2, i64 0, i64 2\n  store {}* %8, {}** %9, align 16\n  %10 = call nonnull {}* @ijl_box_int64(i64 signext %0)\n  %11 = getelementptr inbounds [4 x {}*], [4 x {}*]* %gcframe2, i64 0, i64 3\n  store {}* %10, {}** %11, align 8\n  store {}* %10, {}** %.sub, align 8\n  %12 = getelementptr inbounds [2 x {}*], [2 x {}*]* %1, i64 0, i64 1\n  store {}* %8, {}** %12, align 8\n  %13 = call nonnull {}* @ijl_apply_generic({}* inttoptr (i64 139778991255216 to {}*), {}** nonnull %.sub, i32 2)\n  %14 = load {}*, {}** %4, align 8\n  %15 = bitcast {}*** %pgcstack to {}**\n  store {}* %14, {}** %15, align 8\n  ret {}* %13\n}\n\n\n\n\nSet type of the global variable\n\nvariable_typed::Int = 10\n\nfunction add_using_global_variable_typed(x)\n    return x + variable_typed\nend\n\n@btime add_using_global_variable_typed(10);\n\n  3.085 ns (0 allocations: 0 bytes)\n\n\n\n\nUse the keyword const\n\nconst constant = 10\n\nfunction add_by_passing_global_constant(x, v)\n    return x + v\nend\n\n@btime add_by_passing_global_constant(10, $constant);\n\n  3.095 ns (0 allocations: 0 bytes)\n\n\n\n\nvariable = 10\n\nfunction sum_variable_many_times(n)\n    total = rand(variable)\n    for i in 1:n\n        total .+= rand(variable)\n    end\n    return total\nend\n\n@btime sum_variable_many_times(100);\n\n  54.431 μs (301 allocations: 20.45 KiB)\n\n\n\n\nconst constant = 10\n\nfunction sum_constant_many_times(n)\n    total = rand(constant)\n    for i in 1:n\n        total .+= rand(constant)\n    end\n    return total\nend\n\n@btime sum_constant_many_times(100);\n\n  8.593 μs (101 allocations: 14.20 KiB)"
  },
  {
    "objectID": "performance/pay-attention-to-memory-allocation.html",
    "href": "performance/pay-attention-to-memory-allocation.html",
    "title": "Memory allocation",
    "section": "",
    "text": "function build_preallocate(n::Int)\n    @assert n &gt;= 2\n    v = zeros(Int64,n)\n    v[1] = 1\n    v[2] = 1\n    for i = 3:n\n        v[i] = v[i-1] + v[i-2]\n    end\n    return v\nend\n\nbuild_preallocate (generic function with 1 method)\n\n\n\n\nfunction build_no_allocation(n::Int)\n    @assert n &gt;= 2\n    v = Vector{Int64}()\n    push!(v,1)\n    push!(v,1)\n    for i = 3:n\n        push!(v,v[i-1]+v[i-2])\n    end\n    return v\nend\n\nbuild_no_allocation (generic function with 1 method)"
  },
  {
    "objectID": "performance/pay-attention-to-memory-allocation.html#functions-with-preallocated-memory-run-faster",
    "href": "performance/pay-attention-to-memory-allocation.html#functions-with-preallocated-memory-run-faster",
    "title": "Memory allocation",
    "section": "",
    "text": "function build_preallocate(n::Int)\n    @assert n &gt;= 2\n    v = zeros(Int64,n)\n    v[1] = 1\n    v[2] = 1\n    for i = 3:n\n        v[i] = v[i-1] + v[i-2]\n    end\n    return v\nend\n\nbuild_preallocate (generic function with 1 method)\n\n\n\n\nfunction build_no_allocation(n::Int)\n    @assert n &gt;= 2\n    v = Vector{Int64}()\n    push!(v,1)\n    push!(v,1)\n    for i = 3:n\n        push!(v,v[i-1]+v[i-2])\n    end\n    return v\nend\n\nbuild_no_allocation (generic function with 1 method)"
  },
  {
    "objectID": "performance/pay-attention-to-memory-allocation.html#whenever-possible-preallocate-memory",
    "href": "performance/pay-attention-to-memory-allocation.html#whenever-possible-preallocate-memory",
    "title": "Memory allocation",
    "section": "Whenever possible, preallocate memory",
    "text": "Whenever possible, preallocate memory\n\nisequal(build_preallocate(10),build_no_allocation(10))\n\ntrue\n\n\n\nusing BenchmarkTools\n\nn = 100\n\n@btime build_no_allocation(n);\n\n@btime build_preallocate(n);\n\n  644.391 ns (4 allocations: 1.92 KiB)\n  160.576 ns (1 allocation: 896 bytes)\n\n\n\njulia --check-bounds=no -O3 --track-allocation=user build_no_allocation.jl\n\ncat build_no_allocation.jl.*.mem\n\n   - function build_no_allocation(n::Int)\n   0     @assert n &gt;= 2\n  64     v = Vector{Int64}()\n  80     push!(v,1)\n   0     push!(v,1)\n   0     for i = 3:n\n1824         push!(v,v[i-1]+v[i-2])\n   0     end\n   0     return v\n   - end\n\njulia --check-bounds=no -O3 --track-allocation=user build_preallocate.jl\n\ncat build_preallocate.jl.*.mem\n\n  - function build_preallocate(n::Int)\n  0     @assert n &gt;= 2\n896     v = zeros(Int64,n)\n  0     v[1] = 1\n  0     v[2] = 1\n  0     for i = 3:n\n  0         v[i] = v[i-1] + v[i-2]\n  0     end\n  0     return v\n  - end"
  },
  {
    "objectID": "performance/pay-attention-to-memory-allocation.html#pre-allocating-outputs",
    "href": "performance/pay-attention-to-memory-allocation.html#pre-allocating-outputs",
    "title": "Memory allocation",
    "section": "Pre-allocating outputs",
    "text": "Pre-allocating outputs\nWhenever you can reuse memory, reuse it.\nYou have a vector b and a vector h where b[i] is the base length of triangle i and h[i] is the height length. The experiment is to find the hypotenuse value of all triangles.\n\nusing BenchmarkTools\n\nb = rand(1000)*10\nh = rand(1000)*10\nfunction find_hypotenuse(b::Vector{T},h::Vector{T}) where T &lt;: Real\n    return sqrt.(b.^2+h.^2)\nend\n\nfind_hypotenuse (generic function with 1 method)\n\n\n\n@btime find_hypotenuse($b, $h);\n\n  3.871 μs (4 allocations: 31.75 KiB)\n\n\n\n\nfunction find_hypotenuse_optimized(b::Vector{T},h::Vector{T}) where T &lt;: Real\n    accum_vec = similar(b)\n    for i = eachindex(accum_vec)\n        accum_vec[i] = b[i]^2\n        accum_vec[i] += h[i]^2 # here, we used the same space in memory to hold the sum\n        accum_vec[i] = sqrt(accum_vec[i]) # same thing here, to hold the sqrt\n    end\n    return accum_vec\nend\n\nfind_hypotenuse_optimized (generic function with 1 method)\n\n\n\n@btime find_hypotenuse_optimized($b, $h);\n\n  2.849 μs (1 allocation: 7.94 KiB)\n\n\n\n\nusing FFTW, LinearAlgebra\n\nxmin, xmax, nx = 0, 4π, 1024\nymin, ymax, ny = 0, 4π, 1024\n\nx = LinRange(xmin, xmax, nx+1)[1:end-1]\ny = LinRange(ymin, ymax, ny+1)[1:end-1]\nky  = 2π ./ (ymax-ymin) .* fftfreq(ny, ny)\nexky = exp.( 1im .* ky .* x')\n\nf  = zeros(ComplexF64, (nx,ny))\nfᵗ = zeros(ComplexF64, reverse(size(f)))\nf̂ᵗ = zeros(ComplexF64, reverse(size(f)))\nf .= sin.(x) .* cos.(y')\n\nplan = plan_fft(fᵗ, 1, flags=FFTW.PATIENT)\n\nFFTW forward plan for 1024×1024 array of ComplexF64\n(dft-vrank&gt;=1-x1024/1\n  (dft-ct-dit/32\n    (dftw-direct-32/248 \"t2fv_32_avx2\")\n    (dft-direct-32-x32 \"n2fv_32_avx2\")))\n\n\n\n\nfunction df_dy_optimized!( f, fᵗ, f̂ᵗ, plan, exky )\n\n    transpose!(fᵗ,f)\n    mul!(f̂ᵗ,  plan, fᵗ)\n    f̂ᵗ .= f̂ᵗ .* exky\n    ldiv!(fᵗ, plan, f̂ᵗ)\n    transpose!(f, fᵗ)\n\nend\n\n@btime df_dy_optimized!($f, $fᵗ, $f̂ᵗ, $plan, $exky );\n\n  12.853 ms (2 allocations: 112 bytes)"
  },
  {
    "objectID": "performance/consider-static-arrays.html",
    "href": "performance/consider-static-arrays.html",
    "title": "StaticArrays.jl",
    "section": "",
    "text": "using DifferentialEquations, BenchmarkTools, Plots\n\n\n\nfunction lorenz(u,p,t)\n dx = 10.0*(u[2]-u[1])\n dy = u[1]*(28.0-u[3]) - u[2]\n dz = u[1]*u[2] - (8/3)*u[3]\n [dx,dy,dz]\nend\n\nlorenz (generic function with 1 method)\n\n\n\nu0 = [1.0;0.0;0.0]\ntspan = (0.0,100.0)\nprob = ODEProblem(lorenz,u0,tspan)\nsol = solve(prob,Tsit5())\nplot(sol,vars=(1,2,3))\n\n┌ Warning: To maintain consistency with solution indexing, keyword argument vars will be removed in a future version. Please use keyword argument idxs instead.\n│   caller = ip:0x0\n└ @ Core :-1\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n@benchmark solve(prob,Tsit5())\n\n\nBenchmarkTools.Trial: 1258 samples with 1 evaluation.\n Range (min … max):  3.300 ms … 8.944 ms  ┊ GC (min … max):  0.00% … 31.36%\n Time  (median):     3.420 ms             ┊ GC (median):     0.00%\n Time  (mean ± σ):   3.971 ms ± 1.117 ms  ┊ GC (mean ± σ):  12.70% ± 17.20%\n  ▂█▅▃▃▄▂▂                                     ▁▁▁▁ ▁        \n  ████████▁▁▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▇█████████▇█▅▇ █\n  3.3 ms      Histogram: log(frequency) by time     6.71 ms &lt;\n Memory estimate: 7.82 MiB, allocs estimate: 101102.\n\n\n\n\n\nfunction lorenz!(du,u,p,t)\n du[1] = 10.0*(u[2]-u[1])\n du[2] = u[1]*(28.0-u[3]) - u[2]\n du[3] = u[1]*u[2] - (8/3)*u[3]\nend\n\nlorenz! (generic function with 1 method)\n\n\n\nu0 = [1.0;0.0;0.0]\ntspan = (0.0,100.0)\nprob = ODEProblem(lorenz!,u0,tspan)\n@benchmark solve(prob,Tsit5())\n\n\nBenchmarkTools.Trial: 7125 samples with 1 evaluation.\n Range (min … max):  566.759 μs …   6.043 ms  ┊ GC (min … max): 0.00% … 58.43%\n Time  (median):     626.149 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   699.188 μs ± 425.344 μs  ┊ GC (mean ± σ):  8.84% ± 11.81%\n  ▃█▄▂                                                          ▁\n  ████▇▅▃▅▇▇▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▅▆█▇ █\n  567 μs        Histogram: log(frequency) by time       3.43 ms &lt;\n Memory estimate: 996.23 KiB, allocs estimate: 11416.\n\n\n\n\nStaticArray is statically-sized (known at compile time) and thus its accesses are quick. Additionally, the exact block of memory is known in advance by the compiler, and thus re-using the memory is cheap. This means that allocating on the stack has essentially no cost!\n\nusing StaticArrays\n\nfunction lorenz_static(u,p,t)\n dx = 10.0*(u[2]-u[1])\n dy = u[1]*(28.0-u[3]) - u[2]\n dz = u[1]*u[2] - (8/3)*u[3]\n @SVector [dx,dy,dz]\nend\n\nlorenz_static (generic function with 1 method)\n\n\n\nu0 = @SVector [1.0,0.0,0.0]\ntspan = (0.0,100.0)\nprob = ODEProblem(lorenz_static,u0,tspan)\n@benchmark solve(prob,Tsit5())\n\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation.\n Range (min … max):  238.301 μs …   7.668 ms  ┊ GC (min … max): 0.00% … 14.37%\n Time  (median):     259.281 μs               ┊ GC (median):    0.00%\n Time  (mean ± σ):   271.050 μs ± 123.027 μs  ┊ GC (mean ± σ):  2.89% ±  6.87%\n         ▆█▆▃▁▃▃▁                                               ▂\n  ▄▄▁▁▁▁▆████████████▇▇▅▆▆▄▅▅▄▁▁▁▃▁▁▃▁▁▁▁▁▃▁▁▁▃▁▁▁▁▁▁▁▁▁▄▆▇▇▇▇▆ █\n  238 μs        Histogram: log(frequency) by time        386 μs &lt;\n Memory estimate: 387.30 KiB, allocs estimate: 1293."
  },
  {
    "objectID": "package.html",
    "href": "package.html",
    "title": "Make a package",
    "section": "",
    "text": "Share your code and maintain it.\nBetter source files organization.\nImprove your programming practices by making tests.\nContinuous integration.\nDocumentation is hosted and generated after every changes."
  },
  {
    "objectID": "package.html#why-make-a-package",
    "href": "package.html#why-make-a-package",
    "title": "Make a package",
    "section": "",
    "text": "Share your code and maintain it.\nBetter source files organization.\nImprove your programming practices by making tests.\nContinuous integration.\nDocumentation is hosted and generated after every changes."
  },
  {
    "objectID": "package.html#configure-git",
    "href": "package.html#configure-git",
    "title": "Make a package",
    "section": "Configure git",
    "text": "Configure git\nGit configuration is used to set the package author.\ngit config --global user.name \"Pierre Navaro\"\ngit config --global user.email \"pierre.navaro@math.cnrs.fr\"\ngit config --global github.user \"pnavaro\""
  },
  {
    "objectID": "package.html#install-some-useful-packages",
    "href": "package.html#install-some-useful-packages",
    "title": "Make a package",
    "section": "Install some useful packages",
    "text": "Install some useful packages\n\nRevise.jl: Automatically update function definitions in a running Julia session. This package is mandatory if you want to develop a package. It is better to ensure that every Julia session uses it.\n\nmkdir -p ~/.julia/config/ && echo \"using Revise\" &gt;&gt; ~/.julia/config/startup.jl\n\nDocumenter.jl: Documentation generator.\nDocumenterTools.jl : Extra tools for setting up Documenter.\nDocStringExtensions.jl: Extensions for Julia’s docsystem.\nJuliaFormatter.jl: code formatter for Julia.\nCompatHelperLocal.jl : Help for [compat] entries\nAqua.jl: Auto QUality Assurance for Julia packages.\nJET.jl : code analyzer for Julia."
  },
  {
    "objectID": "package.html#create-the-julia-package-temperature",
    "href": "package.html#create-the-julia-package-temperature",
    "title": "Make a package",
    "section": "Create the Julia package Temperature",
    "text": "Create the Julia package Temperature\n(v1.0) pkg&gt; generate Temperature\nGenerating project Temperature:\n    Temeperatures/Project.toml\n    Temeperatures/src/Temperature.jl\nshell&gt; cat Temperature/Project.toml\nauthors = [\"Pierre Navaro &lt;pierre.navaro@math.cnrs.fr&gt;\"]\nname = \"Temperature\"\nuuid = \"417a5b38-18da-11e9-35ce-9bdc85ad86c9\"\nversion = \"0.1.0\"\n\n[deps]"
  },
  {
    "objectID": "package.html#activate-your-package",
    "href": "package.html#activate-your-package",
    "title": "Make a package",
    "section": "Activate your package",
    "text": "Activate your package\n(v1.0) pkg&gt; activate .\n\n(Temperature) pkg&gt; instantiate"
  },
  {
    "objectID": "package.html#add-dependencies",
    "href": "package.html#add-dependencies",
    "title": "Make a package",
    "section": "Add dependencies",
    "text": "Add dependencies\n(Temperature) pkg&gt; add DocStringExtensions\nThe Manifest.toml allows someone to replicate the exact version of the dependencies that was recorded in the manifest on e.g. another machine. For a package that is to be used as a library, this is not useful.\nHowever, for an “application”, i.e. something at “top level” (say your julia code to do the simulations in a scientific paper) then it is likely useful to be able to replicate that exact state and the Manifest is thus useful to check in."
  },
  {
    "objectID": "package.html#check-the-documentation",
    "href": "package.html#check-the-documentation",
    "title": "Make a package",
    "section": "Check the documentation",
    "text": "Check the documentation\n\njulia&gt; using Temperature\n\nhelp?&gt; celsius"
  },
  {
    "objectID": "package.html#add-a-test",
    "href": "package.html#add-a-test",
    "title": "Make a package",
    "section": "Add a test",
    "text": "Add a test\ncd Temperature\nmkdir test\nadd file runtests.jl\nshell&gt; cat test/runtests.jl\nusing Temperature\n\n@testset \"convert Celsius to Fahrenheit\" begin\n\n    @test fahrenheit(0.0) == 32.0\n\nend\nImplement the fahrenheit function in src/Temperature.jl\nfahrenheit(t) = ( t + 32) * 9 / 5"
  },
  {
    "objectID": "package.html#verify-the-test",
    "href": "package.html#verify-the-test",
    "title": "Make a package",
    "section": "Verify the test",
    "text": "Verify the test\n(Temperature) pkg&gt; test\n   Testing Temperature\n Resolving package versions...\nTest Summary:             | Pass  Total\nTest convert Celsius to Fahrenheit |    1      1\n   Testing Temperature tests passed\nExercises :\n\nAdd a new test for fahrenheit(20)\nLaunch tests\nImplement two tests for the inverse function named celsius\nImplement the function\nLaunch tests"
  },
  {
    "objectID": "package.html#documentation",
    "href": "package.html#documentation",
    "title": "Make a package",
    "section": "Documentation",
    "text": "Documentation\nhttps://github.com/JuliaDocs/Documenter.jl\njulia&gt; using DocumenterTools\nshell&gt; pwd\n/Users/navaro/JuliaProjects/Temperature\njulia&gt; DocumenterTools.generate(\"docs\")\n[ Info: name of package automatically determined to be `Temperature`.\n[ Info: deploying documentation to `~/JuliaProjects/Temperature/docs`\n[ Info: Generating .gitignore at /Users/navaro/JuliaProjects/Temperature/docs/.gitignore\n[ Info: Generating make.jl at /Users/navaro/JuliaProjects/Temperature/docs/make.jl\n[ Info: Generating Project.toml at /Users/navaro/JuliaProjects/Temperature/docs/Project.toml\n[ Info: Generating src/index.md at /Users/navaro/JuliaProjects/Temperature/docs/src/index.md\nshell&gt; cat docs/src/index.md\n# Temperature.jl\n\nDocumentation for Temperature.jl\n\n## Types and Functions\n```@autodocs\nModules = [Temperature]\nOrder   = [:type, :function]\n```\nshell&gt; cat docs/make.jl\n\nusing Documenter\nusing Temperature\nusing Plots\n\nENV[\"GKSwstype\"] = \"100\" # Avoid issues with display when generating documentation\n\nmakedocs(modules=[Temperature],\n         doctest = false,\n         format = Documenter.HTML(),\n         sitename = \"Temperature.jl\",\n         pages = [\"Documentation\"    =&gt; \"index.md\"])\n\ndeploydocs(\n    repo   = \"github.com/pnavaro/Temperature.jl.git\"\n )\nIs is possible to add BibTeX citations and references in documentation pages with DocumenterCitations.jl."
  },
  {
    "objectID": "package.html#codecov",
    "href": "package.html#codecov",
    "title": "Make a package",
    "section": "Codecov",
    "text": "Codecov\nAdd your repository by going to https://codecov.io/gh\nlanguage: julia\n\nos:\n  - linux\n  - osx\n\njulia:\n  - 1.0\n  - nightly\n\nnotifications:\n  email: true\n\nafter_success:\n    - julia -e 'using Pkg; cd(Pkg.dir(\"Temperature\")); Pkg.add(\"Coverage\"); using Coverage; Codecov.submit(process_folder())'\n\njobs:\n  include:\n    - stage: \"Documentation\"\n      julia: 1.0\n      os: linux\n      script:\n        - julia --project=docs/ -e 'using Pkg; Pkg.develop(PackageSpec(path=pwd())); Pkg.instantiate()'\n        - julia --project=docs/ docs/make.jl\n      name: \"HTML\"\n      after_success: skip"
  },
  {
    "objectID": "package.html#hosting-your-documentation-on-github-pages",
    "href": "package.html#hosting-your-documentation-on-github-pages",
    "title": "Make a package",
    "section": "Hosting your documentation on Github pages",
    "text": "Hosting your documentation on Github pages\nLaunch julia in your package directory.\npkg&gt; add DocumenterTools\npkg&gt; activate .\njulia&gt; using DocumenterTools\njulia&gt; using Temperature\njulia&gt; DocumenterTools.genkeys(Temperature)\nFollow the instructions that are printed out\n\nAdd the public ssh key to your settings page for the GitHub repository.\nDon’t forget to check Allow write access to allow Documenter to commit the generated documentation to the repo."
  },
  {
    "objectID": "package.html#badges",
    "href": "package.html#badges",
    "title": "Make a package",
    "section": "Badges",
    "text": "Badges\nIt is common practice to make use of “badges” for build status, code coverage and documentation. Adding the following to your package README.md should be all that is necessary:\n\nCodecov badge : https://codecov.io/gh/pnavaro/Temperature.jl/settings/badge\n\n[![Build Status](https://github.com/pnavaro/Temperature.jl/actions/workflows/CI.yml/badge.svg?branch=main)]\n[![codecov](https://codecov.io/gh/pnavaro/Temperature.jl/branch/main/graph/badge.svg)](https://codecov.io/gh/pnavaro/Temperature.jl)\n[![](https://img.shields.io/badge/docs-stable-blue.svg)](https://pnavaro.github.io/Temperature.jl/stable)\n[![](https://img.shields.io/badge/docs-dev-blue.svg)](https://pnavaro.github.io/Temperature.jl/dev)"
  },
  {
    "objectID": "package.html#register-your-package",
    "href": "package.html#register-your-package",
    "title": "Make a package",
    "section": "Register your package",
    "text": "Register your package\n\nSet up AttoBot on your repository.\nYou need to tag your verson with git (for example v0.1.0)\nUse Github releases.\nWait a couple of days.\n\nI did not do it for Temperature"
  },
  {
    "objectID": "package.html#items-not-covered",
    "href": "package.html#items-not-covered",
    "title": "Make a package",
    "section": "Items not covered",
    "text": "Items not covered\n\nBinary package PackageCompiler.jl\nMixed language BinDeps.jl\nCreate a pdf with Documenter\nLiterate.jl : create markdown file and/or jupyter notebook from a julia program. Easy way to create your examples and tutorials."
  },
  {
    "objectID": "diffeq/runge-kutta.html",
    "href": "diffeq/runge-kutta.html",
    "title": "Runge-Kutta methods",
    "section": "",
    "text": "using Plots\nWe will implement in Julia different numerical methods to solve\n\\[\ny'(t) = 1 - y(t)\n\\]\n\\[ t \\in [0,5] \\qquad \\mbox{ and } \\qquad y(0) = 0 \\]"
  },
  {
    "objectID": "diffeq/runge-kutta.html#explicit-euler",
    "href": "diffeq/runge-kutta.html#explicit-euler",
    "title": "Runge-Kutta methods",
    "section": "Explicit Euler",
    "text": "Explicit Euler\n\n\"\"\"\n   euler(f, t, y, h)\n\nexplicit euler method function that returns\n\n``y^{n+1} = y^n + h \\\\cdot f(t^n, y^n)``\n\"\"\"\nfunction euler(f::Function, t::Float64, y::Float64, h::Float64)\n    t + h, y + h * f(t,y)\nend\n\neuler\n\n\n\n?euler\n\nsearch: euler schedule NamedTuple promote_rule baremodule @NamedTuple\n\n\n\neuler(f, t, y, h)\nexplicit euler method function that returns\n\\(y^{n+1} = y^n + h \\cdot f(t^n, y^n)\\)"
  },
  {
    "objectID": "diffeq/runge-kutta.html#runge-kutta-2nd-order",
    "href": "diffeq/runge-kutta.html#runge-kutta-2nd-order",
    "title": "Runge-Kutta methods",
    "section": "Runge-Kutta 2nd order",
    "text": "Runge-Kutta 2nd order\n\n\"\"\"\n\n   rk2(f, t, y,  dt)\n\nRunge-Kutta second order method function\n\n\"\"\"\nfunction rk2(f::Function, t::Float64, y::Float64,  h::Float64)\n    ỹ = y + h/2 * f(t,y)\n    t + h, y + h * f(t+h/2,ỹ)\nend\n\nrk2"
  },
  {
    "objectID": "diffeq/runge-kutta.html#runge-kutta-4th-order",
    "href": "diffeq/runge-kutta.html#runge-kutta-4th-order",
    "title": "Runge-Kutta methods",
    "section": "Runge-Kutta 4th order",
    "text": "Runge-Kutta 4th order\n\n\"\"\"\n\n   rk4(f::Function, t::Float64, y::Float64,  dt::Float64)\n\nRunge-Kutta fourth order method function\n\n[Runge–Kutta methods on Wikipedia](https://en.wikipedia.org/wiki/Runge–Kutta_methods)\n\n\"\"\"\nfunction rk4(f::Function, t::Float64, y::Float64,  dt::Float64)\n\n    y₁ = dt * f(t,y)\n    y₂ = dt * f(t+dt/2,y+y₁/2)\n    y₃ = dt * f(t+dt/2,y+y₂/2)\n    y₄ = dt * f(t+dt,y+y₃)\n\n    t+dt, y+(y₁+2*y₂+2*y₃+y₄)/6\nend\n\nrk4"
  },
  {
    "objectID": "diffeq/runge-kutta.html#solver-function",
    "href": "diffeq/runge-kutta.html#solver-function",
    "title": "Runge-Kutta methods",
    "section": "Solver function",
    "text": "Solver function\n\n\"\"\"\n\n    solver(f::Function, df::Function, t₀::Float64,\n                y₀::Float64, dt::Float64, nsteps::Int64)\n\nSolve numerically the equation ``y' = f(t, y)``\n\nwith `y(t₀)= y₀` and `nsteps` steps `h`\n\n## Arguments\n- `f::Function`: the function `f` of equation ``y' = f(t,y)``.\n- `df::Function`: numerical method from (tⁿ,yⁿ) returns ``(t^{n+1},y^{n+1})``\n\n\n\"\"\"\nfunction solver(f::Function,\n                df::Function,\n                t₀::Float64,\n                y₀::Float64, h::Float64, nsteps::Int64)\n\n    t = zeros(Float64,nsteps)\n    y = similar(t)\n\n    t[1] = t₀\n    y[1] = y₀\n\n    for i in 2:nsteps\n       t[i], y[i] = df(f,t[i-1],y[i-1], h)\n    end\n\n    t, y\n\nend\n\nsolver\n\n\n\n?solver\n\nsearch: solver\n\n\n\nsolver(f::Function, df::Function, t₀::Float64,\n            y₀::Float64, dt::Float64, nsteps::Int64)\nSolve numerically the equation \\(y' = f(t, y)\\)\nwith y(t₀)= y₀ and nsteps steps h\n\nArguments\n\nf::Function: the function f of equation \\(y' = f(t,y)\\).\ndf::Function: numerical method from (tⁿ,yⁿ) returns \\((t^{n+1},y^{n+1})\\)\n\n\n\n\n\nnsteps, tfinal   = 7, 5.0\nt₀, x₀ = 0., 0.\n\n(0.0, 0.0)\n\n\n\ndt = tfinal / (nsteps-1)\nf(t, x) = 1 - x\n\nf (generic function with 1 method)\n\n\n\nplot( solver(f, euler, t₀, x₀, dt, nsteps); marker = :o, label=\"euler\")\nplot!(solver(f, rk2,   t₀, x₀, dt, nsteps); marker = :d, label=\"rk2\")\nplot!(solver(f, rk4,   t₀, x₀, dt, nsteps); marker = :p, label=\"rk4\")\nt = 0:0.1:5\nplot!(t, 1 .- exp.(-t); line = 3, label = \"exact\")"
  },
  {
    "objectID": "diffeq/runge-kutta.html#arguments",
    "href": "diffeq/runge-kutta.html#arguments",
    "title": "Runge-Kutta methods",
    "section": "Arguments",
    "text": "Arguments\n\nf::Function: the function f of equation \\(y' = f(t,y)\\).\ndf::Function: numerical method from (tⁿ,yⁿ) returns \\((t^{n+1},y^{n+1})\\)"
  },
  {
    "objectID": "diffeq/poisson-equation.html",
    "href": "diffeq/poisson-equation.html",
    "title": "Poisson Equation",
    "section": "",
    "text": "\\[\n\\frac{\\partial^2 u}{\\partial x^2} = b  \\qquad x \\in [0,1]\n\\]\nWe solve only interior points: the endpoints are set to zero.\n\\[\nu(0) = u(1) = 0, \\qquad b = \\sin(2\\pi x)\n\\]\n\nusing Plots, BenchmarkTools\n\n\nfunction plot_solution(x, u)\n    plot([0;x;1],[0;u;0], label=\"computed\")\n    scatter!([0;x;1],-sin.(2π*[0;x;1])/(4π^2),label=\"exact\")\nend\n\nplot_solution (generic function with 1 method)\n\n\n\nΔx = 0.05\nx = Δx:Δx:1-Δx \nN = length(x)\n\n19\n\n\n\nA = zeros(N,N)\nfor i in 1:N, j in 1:N\n    abs(i-j) &lt;= 1 && (A[i,j] +=1)\n    i==j          && (A[i,j] -=3)\nend\n\n\nB = sin.(2π*x) * Δx^2\nu = A \\ B\n\n19-element Vector{Float64}:\n -0.007892189393343806\n -0.015011836300750243\n -0.020662020077425496\n -0.024289661368163386\n -0.025539661368163387\n -0.024289661368163386\n -0.0206620200774255\n -0.015011836300750247\n -0.007892189393343808\n -1.5770213417970973e-18\n  0.007892189393343803\n  0.015011836300750236\n  0.02066202007742549\n  0.024289661368163375\n  0.025539661368163376\n  0.02428966136816338\n  0.020662020077425493\n  0.015011836300750241\n  0.007892189393343805\n\n\n\nplot_solution(x, u)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSparseArrays\n\nusing SparseArrays\n\n\nΔx = 0.05\nx = Δx:Δx:1-Δx \nN = length(x)\nB = sin.(2π*x) * Δx^2\n\n19-element Vector{Float64}:\n  0.0007725424859373687\n  0.001469463130731183\n  0.002022542485937369\n  0.0023776412907378845\n  0.0025000000000000005\n  0.0023776412907378845\n  0.002022542485937369\n  0.0014694631307311833\n  0.0007725424859373689\n  3.0616169978683835e-19\n -0.0007725424859373683\n -0.0014694631307311829\n -0.002022542485937369\n -0.0023776412907378845\n -0.0025000000000000005\n -0.0023776412907378845\n -0.0020225424859373693\n -0.0014694631307311838\n -0.0007725424859373692\n\n\n\nP = spdiagm( -1 =&gt;    ones(Float64,N-1),\n              0 =&gt; -2*ones(Float64,N),\n              1 =&gt;    ones(Float64,N-1))\n\n19×19 SparseMatrixCSC{Float64, Int64} with 55 stored entries:\n⎡⠻⣦⡀⠀⠀⠀⠀⠀⠀⠀⎤\n⎢⠀⠈⠻⣦⡀⠀⠀⠀⠀⠀⎥\n⎢⠀⠀⠀⠈⠻⣦⡀⠀⠀⠀⎥\n⎢⠀⠀⠀⠀⠀⠈⠻⣦⡀⠀⎥\n⎣⠀⠀⠀⠀⠀⠀⠀⠈⠻⠆⎦\n\n\n\nu = P \\ B\n\n19-element Vector{Float64}:\n -0.007892189393343805\n -0.015011836300750241\n -0.020662020077425496\n -0.024289661368163382\n -0.025539661368163383\n -0.024289661368163386\n -0.0206620200774255\n -0.015011836300750248\n -0.007892189393343811\n -6.308085367188389e-18\n  0.0078921893933438\n  0.01501183630075024\n  0.020662020077425496\n  0.024289661368163382\n  0.025539661368163387\n  0.024289661368163386\n  0.020662020077425496\n  0.015011836300750243\n  0.007892189393343806\n\n\n\nplot_solution(x, u)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinearAlgebra\n\nusing LinearAlgebra\n\n\nΔx = 0.05\nx = Δx:Δx:1-Δx \nN = length(x)\nB = sin.(2π*x) * Δx^2\n\n19-element Vector{Float64}:\n  0.0007725424859373687\n  0.001469463130731183\n  0.002022542485937369\n  0.0023776412907378845\n  0.0025000000000000005\n  0.0023776412907378845\n  0.002022542485937369\n  0.0014694631307311833\n  0.0007725424859373689\n  3.0616169978683835e-19\n -0.0007725424859373683\n -0.0014694631307311829\n -0.002022542485937369\n -0.0023776412907378845\n -0.0025000000000000005\n -0.0023776412907378845\n -0.0020225424859373693\n -0.0014694631307311838\n -0.0007725424859373692\n\n\n\nDU =  ones(Float64, N-1)\nD = -2ones(Float64, N)\nDL =  ones(Float64, N-1)\n\n18-element Vector{Float64}:\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n\n\n\nT = Tridiagonal(DL, D, DU)\n\n19×19 Tridiagonal{Float64, Vector{Float64}}:\n -2.0   1.0    ⋅     ⋅     ⋅     ⋅   …    ⋅     ⋅     ⋅     ⋅     ⋅     ⋅ \n  1.0  -2.0   1.0    ⋅     ⋅     ⋅        ⋅     ⋅     ⋅     ⋅     ⋅     ⋅ \n   ⋅    1.0  -2.0   1.0    ⋅     ⋅        ⋅     ⋅     ⋅     ⋅     ⋅     ⋅ \n   ⋅     ⋅    1.0  -2.0   1.0    ⋅        ⋅     ⋅     ⋅     ⋅     ⋅     ⋅ \n   ⋅     ⋅     ⋅    1.0  -2.0   1.0       ⋅     ⋅     ⋅     ⋅     ⋅     ⋅ \n   ⋅     ⋅     ⋅     ⋅    1.0  -2.0  …    ⋅     ⋅     ⋅     ⋅     ⋅     ⋅ \n   ⋅     ⋅     ⋅     ⋅     ⋅    1.0       ⋅     ⋅     ⋅     ⋅     ⋅     ⋅ \n   ⋅     ⋅     ⋅     ⋅     ⋅     ⋅        ⋅     ⋅     ⋅     ⋅     ⋅     ⋅ \n   ⋅     ⋅     ⋅     ⋅     ⋅     ⋅        ⋅     ⋅     ⋅     ⋅     ⋅     ⋅ \n   ⋅     ⋅     ⋅     ⋅     ⋅     ⋅        ⋅     ⋅     ⋅     ⋅     ⋅     ⋅ \n   ⋅     ⋅     ⋅     ⋅     ⋅     ⋅   …    ⋅     ⋅     ⋅     ⋅     ⋅     ⋅ \n   ⋅     ⋅     ⋅     ⋅     ⋅     ⋅        ⋅     ⋅     ⋅     ⋅     ⋅     ⋅ \n   ⋅     ⋅     ⋅     ⋅     ⋅     ⋅       1.0    ⋅     ⋅     ⋅     ⋅     ⋅ \n   ⋅     ⋅     ⋅     ⋅     ⋅     ⋅      -2.0   1.0    ⋅     ⋅     ⋅     ⋅ \n   ⋅     ⋅     ⋅     ⋅     ⋅     ⋅       1.0  -2.0   1.0    ⋅     ⋅     ⋅ \n   ⋅     ⋅     ⋅     ⋅     ⋅     ⋅   …    ⋅    1.0  -2.0   1.0    ⋅     ⋅ \n   ⋅     ⋅     ⋅     ⋅     ⋅     ⋅        ⋅     ⋅    1.0  -2.0   1.0    ⋅ \n   ⋅     ⋅     ⋅     ⋅     ⋅     ⋅        ⋅     ⋅     ⋅    1.0  -2.0   1.0\n   ⋅     ⋅     ⋅     ⋅     ⋅     ⋅        ⋅     ⋅     ⋅     ⋅    1.0  -2.0\n\n\n\nu = T \\ B\n\n19-element Vector{Float64}:\n -0.007892189393343806\n -0.015011836300750243\n -0.020662020077425496\n -0.024289661368163386\n -0.025539661368163387\n -0.024289661368163386\n -0.0206620200774255\n -0.015011836300750247\n -0.007892189393343808\n -1.5770213417970973e-18\n  0.007892189393343803\n  0.015011836300750236\n  0.02066202007742549\n  0.024289661368163375\n  0.025539661368163376\n  0.02428966136816338\n  0.020662020077425493\n  0.015011836300750241\n  0.007892189393343805\n\n\n\nplot_solution(x, u)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLAPACK\n\nusing LinearAlgebra\n\n\nΔx = 0.05\nx = Δx:Δx:1-Δx ## Solve only interior points: the endpoints are set to zero.\nN = length(x)\nB = sin.(2π*x) * Δx^2\n\n19-element Vector{Float64}:\n  0.0007725424859373687\n  0.001469463130731183\n  0.002022542485937369\n  0.0023776412907378845\n  0.0025000000000000005\n  0.0023776412907378845\n  0.002022542485937369\n  0.0014694631307311833\n  0.0007725424859373689\n  3.0616169978683835e-19\n -0.0007725424859373683\n -0.0014694631307311829\n -0.002022542485937369\n -0.0023776412907378845\n -0.0025000000000000005\n -0.0023776412907378845\n -0.0020225424859373693\n -0.0014694631307311838\n -0.0007725424859373692\n\n\n\nDU =   ones(Float64, N-1)\nD  = -2ones(Float64, N)\nDL =   ones(Float64, N-1)\n\n18-element Vector{Float64}:\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n 1.0\n\n\n\nLAPACK.gtsv!(DL, D, DU, B)\n\n19-element Vector{Float64}:\n -0.007892189393343806\n -0.015011836300750243\n -0.020662020077425496\n -0.024289661368163386\n -0.025539661368163387\n -0.024289661368163386\n -0.0206620200774255\n -0.015011836300750247\n -0.007892189393343808\n -1.5770213417970973e-18\n  0.007892189393343803\n  0.015011836300750236\n  0.02066202007742549\n  0.024289661368163375\n  0.025539661368163376\n  0.02428966136816338\n  0.020662020077425493\n  0.015011836300750241\n  0.007892189393343805\n\n\n\nplot_solution(x, B)"
  },
  {
    "objectID": "basics/index.html",
    "href": "basics/index.html",
    "title": "Julia shell",
    "section": "",
    "text": "Download for your plaform at http://julialang.org/downloads/\njuliaup is a cross-platform installer useful to install specific Julia versions.\nHomebrew is the best way to install Julia on macOS.\nMost Linux distributions come with Julia packages in their repositories. However, these may lag somewhat behind the current rather fast development cycle."
  },
  {
    "objectID": "basics/index.html#installation",
    "href": "basics/index.html#installation",
    "title": "Julia shell",
    "section": "",
    "text": "Download for your plaform at http://julialang.org/downloads/\njuliaup is a cross-platform installer useful to install specific Julia versions.\nHomebrew is the best way to install Julia on macOS.\nMost Linux distributions come with Julia packages in their repositories. However, these may lag somewhat behind the current rather fast development cycle."
  },
  {
    "objectID": "basics/index.html#run-julia-code.",
    "href": "basics/index.html#run-julia-code.",
    "title": "Julia shell",
    "section": "Run julia code.",
    "text": "Run julia code.\nJulia programs use “.jl” extension by convention and can be executed in the julia prompt with:\ninclude(\"my_program.jl\")\n\nJulia is first translated into an intermediate representation.\nThen LLVM compiles it for your machine.\n\nThis means that\n\nre-running the same code is faster the second time around\nit runs at speeds comparable to compiled C or Fortran code"
  },
  {
    "objectID": "basics/index.html#ide",
    "href": "basics/index.html#ide",
    "title": "Julia shell",
    "section": "IDE",
    "text": "IDE\n\nJulia shell\nCommand line : julia my_program.jl\nJulia notebooks (Jupyter)\nVS Code\n\nI personally use Jupyter for development but VScode seems to be the most used environment."
  },
  {
    "objectID": "basics/index.html#packages",
    "href": "basics/index.html#packages",
    "title": "Julia shell",
    "section": "Packages",
    "text": "Packages\n\nUse ] to switch to package manager.\n\npkg&gt; add IJulia\nwill install the package. Type help to display all available commands.\nUse “backspace” to go back to the julia shell.\nhttps://pkg.julialang.org\nThe package is installed in directory ~/.julia/\nTo import the package, type:\nusing IJulia"
  },
  {
    "objectID": "basics/index.html#jupyter-notebook",
    "href": "basics/index.html#jupyter-notebook",
    "title": "Julia shell",
    "section": "Jupyter notebook",
    "text": "Jupyter notebook\nThe Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\ntype:\nusing IJulia\nnotebook()  # use notebook(detached=true) \nTo convert a notebook file .ipynb in julia program .jl:\n\nIn the top menu File-&gt;Download as\nCommand line : ipython nbconvert --to script my_notebook.ipynb."
  },
  {
    "objectID": "diffeq/gpu.html",
    "href": "diffeq/gpu.html",
    "title": "GPU",
    "section": "",
    "text": "using BenchmarkTools\nusing CUDA\nusing Random\nusing Test\nusing LinearAlgebra\nusing ForwardDiff\nusing ProgressMeter\nusing Plots\nCUDA.version()\nUseful function to enable GPU version of your code\nCUDA.functional()\nfor device in CUDA.devices()\n    @show capability(device)\n    @show name(device)\nend"
  },
  {
    "objectID": "diffeq/gpu.html#array-programming",
    "href": "diffeq/gpu.html#array-programming",
    "title": "GPU",
    "section": "Array programming",
    "text": "Array programming\n\nConstruction\n\na = CuArray{Float32,2}(undef, 2, 2)\n\n\nsimilar(a)\n\n\na = CuArray([1,2,3])"
  },
  {
    "objectID": "diffeq/gpu.html#transfer-to-cpu",
    "href": "diffeq/gpu.html#transfer-to-cpu",
    "title": "GPU",
    "section": "Transfer to CPU",
    "text": "Transfer to CPU\nb is allocated on the CPU, a data transfer is made\n\nb = Array(a)\n\n\ncollect(a)\n\n\nAPI compatibilty with Base.Array\n\nCUDA.ones(2)\n\n\na = CUDA.zeros(Float32, 2)\n\n\na isa AbstractArray\n\n\nCUDA.fill(42, (3,4))"
  },
  {
    "objectID": "diffeq/gpu.html#random-numbers",
    "href": "diffeq/gpu.html#random-numbers",
    "title": "GPU",
    "section": "Random numbers",
    "text": "Random numbers\n\nCUDA.rand(2, 2)\n\n\nCUDA.randn(2, 1)\n\n\nx = CUDA.CuArray(0:0.01:1.0)\nnt = length(x)\ny = 0.2 .+ 0.5 .* x + 0.1 .* CUDA.randn(nt);\nscatter( Array(x), Array(y))\nplot!( x -&gt; 0.2 + 0.5x)\nxlims!(0,1)\nylims!(0,1)\n\n\nX = hcat(CUDA.ones(nt), x);\n\n\nβ = X'X \\ X'y\n\n\nsum( ( β[1] .+ β[2] .* x .- y).^2 )\n\n\na = CuArray([1 2 3])\n\n\nview(a, 2:3)\n\n\na = CuArray{Float64}([1 2 3])\nb = CuArray{Float64}([4 5 6])\n\nmap(a) do x\n    x + 1\nend\n\n\nreduce(+, a)\n\n\naccumulate(+, b; dims=2)\n\n\nfindfirst(isequal(2), a)\n\n\na = CuArray([1 2 3])\nb = CuArray([4 5 6])\n\nmap(a) do x\n    x + 1\nend\n\na .+ 2b\n\nreduce(+, a)\n\naccumulate(+, b; dims=2)\n\nfindfirst(isequal(2), a)"
  },
  {
    "objectID": "diffeq/gpu.html#workflow",
    "href": "diffeq/gpu.html#workflow",
    "title": "GPU",
    "section": "Workflow",
    "text": "Workflow\nA typical approach for porting or developing an application for the GPU is as follows:\n\ndevelop an application using generic array functionality, and test it on the CPU with the Array type\nport your application to the GPU by switching to the CuArray type\ndisallow the CPU fallback (“scalar indexing”) to find operations that are not implemented for or incompatible with GPU execution\n(optional) use lower-level, CUDA-specific interfaces to implement missing functionality or optimize performance"
  },
  {
    "objectID": "diffeq/gpu.html#linear-regression-example",
    "href": "diffeq/gpu.html#linear-regression-example",
    "title": "GPU",
    "section": "Linear regression example",
    "text": "Linear regression example\n\n# squared error loss function\nloss(w, b, x, y) = sum(abs2, y - (w*x .+ b)) / size(y, 2)\n# get gradient w.r.t to `w`\nloss∇w(w, b, x, y) = ForwardDiff.gradient(w -&gt; loss(w, b, x, y), w)\n# get derivative w.r.t to `b` (`ForwardDiff.derivative` is\n# used instead of `ForwardDiff.gradient` because `b` is\n# a scalar instead of an array)\nlossdb(w, b, x, y) = ForwardDiff.derivative(b -&gt; loss(w, b, x, y), b)\n\n\n# proximal gradient descent function\nfunction train(w, b, x, y; lr=0.1)\n    w -= lmul!(lr, loss∇w(w, b, x, y))\n    b -= lr * lossdb(w, b, x, y)\n    return w, b\nend\n\n\nfunction cpu_test(n = 1000, p = 100, iter = 100)\n    x = randn(n, p)'\n    y = sum(x[1:5,:]; dims=1) .+ randn(n)' * 0.1\n    w = 0.0001 * randn(1, p)\n    b = 0.0\n    for i = 1:iter\n       w, b = train(w, b, x, y)\n    end\n    return loss(w,b,x,y)\nend\n\n\n@time cpu_test()\n\n\nMoving to GPU\n\nfunction gpu_test( n = 1000, p = 100, iter = 100)\n    x = randn(n, p)'\n    y = sum(x[1:5,:]; dims=1) .+ randn(n)' * 0.1\n    w = 0.0001 * randn(1, p)\n    b = 0.0\n    x = CuArray(x)\n    y = CuArray(y)\n    w = CuArray(w)\n    \n    for i = 1:iter\n       w, b = train(w, b, x, y)\n       \n    end\n    return loss(w,b,x,y)\nend\n\n\n@time gpu_test()\n\n\n@btime cpu_test( 10000, 100, 100)\n\n\n@btime gpu_test( 10000, 100, 100);"
  },
  {
    "objectID": "diffeq/gpu.html#gpu-programming-performance-tips",
    "href": "diffeq/gpu.html#gpu-programming-performance-tips",
    "title": "GPU",
    "section": "GPU programming performance tips",
    "text": "GPU programming performance tips\n\nAvoid thread divergence\nReduce and coalesce global accesses\nImprove occupancy\nEarly-free arrays CuArrays.unsafe_free!\nAnnotate with @inbounds\nUse 32 bits for float and integers"
  },
  {
    "objectID": "diffeq/rotation-with-fft.html",
    "href": "diffeq/rotation-with-fft.html",
    "title": "Rotation using FFT",
    "section": "",
    "text": "\\[\n\\frac{d f}{dt} +  (v \\frac{d f}{dx} - x \\frac{d f}{dv}) = 0\n\\]\n\\[\nx \\in [-\\pi, \\pi],\\qquad y \\in [-\\pi, \\pi] \\qquad \\mbox{ and } \\qquad t \\in [0, 200\\pi]\n\\]\nusing BenchmarkTools\nusing FFTW\nusing LinearAlgebra\nusing Plots"
  },
  {
    "objectID": "diffeq/rotation-with-fft.html#julia-type-for-mesh-information",
    "href": "diffeq/rotation-with-fft.html#julia-type-for-mesh-information",
    "title": "Rotation using FFT",
    "section": "Julia type for mesh information",
    "text": "Julia type for mesh information\nstruct OneDMesh\n    xmin :: Float64\n    xmax :: Float64\n    nx   :: Int\nend\n\nOneDMesh( -π, π, 128)\n\nstruct TwoDMesh\n    \n    nx   :: Int\n    ny   :: Int\n    xmin :: Float64\n    xmax :: Float64\n    ymin :: Float64\n    ymax :: Float64\n    dx   :: Float64\n    dy   :: Float64\n    x    :: Vector{Float64}\n    y    :: Vector{Float64}\n    \n    function TwoDMesh( xmin, xmax, nx, ymin, ymax, ny)\n        dx, dy = (xmax-xmin)/nx, (ymax-ymin)/ny\n        x = LinRange(xmin, xmax, nx+1)[1:end-1]  # we remove the end point\n        y = LinRange(ymin, ymax, ny+1)[1:end-1]  # for periodic boundary condition\n        new( nx, ny, xmin, xmax, ymin, ymax, dx, dy, x, y)\n    end\nend\n\n\nmesh = TwoDMesh(-π, π, 128, -π, π, 256)\n\nTwoDMesh(128, 256, -3.141592653589793, 3.141592653589793, -3.141592653589793, 3.141592653589793, 0.04908738521234052, 0.02454369260617026, [-3.141592653589793, -3.0925052683774523, -3.043417883165112, -2.9943304979527716, -2.9452431127404313, -2.89615572752809, -2.84706834231575, -2.7979809571034093, -2.748893571891069, -2.699806186678728  …  2.650718801466388, 2.6998061866787286, 2.748893571891069, 2.7979809571034098, 2.8470683423157497, 2.8961557275280905, 2.9452431127404317, 2.9943304979527716, 3.0434178831651124, 3.0925052683774528], [-3.141592653589793, -3.117048960983623, -3.0925052683774528, -3.0679615757712826, -3.0434178831651124, -3.0188741905589414, -2.994330497952771, -2.969786805346601, -2.945243112740431, -2.9206994201342606  …  2.8961557275280905, 2.9206994201342606, 2.945243112740431, 2.969786805346601, 2.994330497952771, 3.0188741905589414, 3.0434178831651124, 3.0679615757712826, 3.0925052683774528, 3.117048960983623])\n\n\n\n@show mesh.xmin, mesh.xmax, mesh.nx, mesh.dx\n\n(mesh.xmin, mesh.xmax, mesh.nx, mesh.dx) = (-3.141592653589793, 3.141592653589793, 128, 0.04908738521234052)\n\n\n(-3.141592653589793, 3.141592653589793, 128, 0.04908738521234052)"
  },
  {
    "objectID": "diffeq/rotation-with-fft.html#create-the-gif-to-show-what-we-are-computing",
    "href": "diffeq/rotation-with-fft.html#create-the-gif-to-show-what-we-are-computing",
    "title": "Rotation using FFT",
    "section": "Create the gif to show what we are computing",
    "text": "Create the gif to show what we are computing\n\nfunction create_gif_animation(mesh, nsteps)\n    \n    @gif for t in LinRange(0, 2π, nsteps)\n\n        f(x,y) = exp(-((cos(t)*x-sin(t)*y)-1)^2/0.2)*exp(-((sin(t)*x+cos(t)*y)-1)^2/0.2)\n        \n        p = plot(mesh.x, mesh.y, f, st = [:contour])\n    \n        plot!(p[1])\n        plot!(zlims=(-0.01,1.01))\n    \n    end\nend\n\ncreate_gif_animation (generic function with 1 method)\n\n\n\ncreate_gif_animation(mesh, 100);\n\n[ Info: Saved animation to /home/runner/work/math-julia/math-julia/tmp.gif"
  },
  {
    "objectID": "diffeq/rotation-with-fft.html#function-to-compute-error",
    "href": "diffeq/rotation-with-fft.html#function-to-compute-error",
    "title": "Rotation using FFT",
    "section": "Function to compute error",
    "text": "Function to compute error\n\nfunction compute_error(f, f_exact)\n    maximum(abs.(f .- f_exact))\nend\n\ncompute_error (generic function with 1 method)"
  },
  {
    "objectID": "diffeq/rotation-with-fft.html#naive-translation-of-a-matlab-code",
    "href": "diffeq/rotation-with-fft.html#naive-translation-of-a-matlab-code",
    "title": "Rotation using FFT",
    "section": "Naive translation of a matlab code",
    "text": "Naive translation of a matlab code\n\nfunction naive_translation_from_matlab(final_time, nsteps, mesh::TwoDMesh)\n\n    dt = final_time/nsteps\n\n    kx = 2π/(mesh.xmax-mesh.xmin) .* fftfreq(mesh.nx, mesh.nx)\n    ky = 2π/(mesh.ymax-mesh.ymin) .* fftfreq(mesh.ny, mesh.ny)\n\n    f = compute_exact_solution(0.0, mesh)\n\n    for n=1:nsteps\n       \n       for (i, x) in enumerate(mesh.x)\n           f[i,:]=real(ifft(exp.(1im*x*ky*tan(dt/2)).*fft(f[i,:])))\n       end\n       \n       for (j, y) in enumerate(mesh.y)\n           f[:,j]=real(ifft(exp.(-1im*y*kx*sin(dt)).*fft(f[:,j])))\n       end\n       \n       for (i, x) in enumerate(mesh.x)\n           f[i,:]=real(ifft(exp.(1im*x*ky*tan(dt/2)).*fft(f[i,:])))\n       end\n   end\n\n   f\nend\n\nnaive_translation_from_matlab (generic function with 1 method)\n\n\n\nnsteps, final_time = 1000, 200\nsol1 = naive_translation_from_matlab(final_time, nsteps, mesh)\nsol2 = compute_exact_solution(final_time, mesh)\nprintln( \" error = \", compute_error(sol1, sol2))\n@btime naive_translation_from_matlab(final_time, nsteps, mesh);\n\n error = 1.9817480989559044e-13\n  10.553 s (7168002 allocations: 7.95 GiB)\n\n\n\nVectorized version\n\nWe remove the for loops over direction x and y by creating the 2d arrays exky and ekxy.\nWe save cpu time by computing them before the loop over time\n\n\nfunction vectorized(final_time, nsteps, mesh::TwoDMesh)\n\n    dt = final_time/nsteps\n\n    kx = 2π/(mesh.xmax-mesh.xmin) .* fftfreq(mesh.nx, mesh.nx)\n    ky = 2π/(mesh.ymax-mesh.ymin) .* fftfreq(mesh.ny, mesh.ny)\n\n    f = compute_exact_solution(0.0, mesh)\n\n    exky = exp.( 1im*tan(dt/2) .* mesh.x  .* ky')\n    ekxy = exp.(-1im*sin(dt)   .* mesh.y' .* kx )\n    \n    for n = 1:nsteps\n        f .= real(ifft(exky .* fft(f, 2), 2))\n        f .= real(ifft(ekxy .* fft(f, 1), 1))\n        f .= real(ifft(exky .* fft(f, 2), 2))\n    end\n\n    f\nend\n\nvectorized (generic function with 1 method)\n\n\n\nnsteps, final_time = 1000, 200\nsol1 = vectorized(final_time, nsteps, mesh)\nsol2 = compute_exact_solution(final_time, mesh)\nprintln( \" error = \", compute_error(sol1, sol2))\n@btime vectorized(final_time, nsteps, mesh);\n\n error = 1.7908811801681452e-13\n  2.174 s (48006 allocations: 6.60 GiB)"
  },
  {
    "objectID": "diffeq/rotation-with-fft.html#inplace-computation",
    "href": "diffeq/rotation-with-fft.html#inplace-computation",
    "title": "Rotation using FFT",
    "section": "Inplace computation",
    "text": "Inplace computation\n\nWe remove the Float64-Complex128 conversion by allocating the distribution function f as a Complex array\nNote that we need to use the inplace assignement operator “.=” to initialize the f array.\nWe use inplace computation for fft with the “bang” operator !\n\n\nfunction inplace(final_time, nsteps, mesh::TwoDMesh)\n\n    dt = final_time/nsteps\n\n    kx = 2π/(mesh.xmax-mesh.xmin)*[0:mesh.nx÷2-1;mesh.nx÷2-mesh.nx:-1]\n    ky = 2π/(mesh.ymax-mesh.ymin)*[0:mesh.ny÷2-1;mesh.ny÷2-mesh.ny:-1]\n    \n    f  = zeros(ComplexF64,(mesh.nx,mesh.ny))\n    f .= compute_exact_solution(0.0, mesh)\n\n    exky = exp.( 1im*tan(dt/2) .* mesh.x  .* ky')\n    ekxy = exp.(-1im*sin(dt)   .* mesh.y' .* kx )\n    \n    for n = 1:nsteps\n        fft!(f, 2)\n        f .= exky .* f\n        ifft!(f,2)\n        fft!(f, 1)\n        f .= ekxy .* f\n        ifft!(f, 1)\n        fft!(f, 2)\n        f .= exky .* f\n        ifft!(f,2)        \n    end\n\n    real(f)\nend\n\ninplace (generic function with 1 method)\n\n\n\nnsteps, final_time = 1000, 200\nsol1 = inplace(final_time, nsteps, mesh)\nsol2 = compute_exact_solution(final_time, mesh)\nprintln( \" error = \", compute_error(sol1, sol2))\n@btime inplace(final_time, nsteps, mesh);\n\n error = 1.8686623861233415e-13\n  1.525 s (18014 allocations: 3.56 MiB)\n\n\n\nUse plans for fft\n\nWhen you apply multiple fft on array with same shape and size, it is recommended to use fftw plan to improve computations.\nLet’s try to initialize our two fft along x and y with plans.\n\n\nfunction with_fft_plans(final_time, nsteps, mesh::TwoDMesh)\n\n    dt = final_time/nsteps\n\n    kx = 2π/(mesh.xmax-mesh.xmin)*[0:mesh.nx÷2-1;mesh.nx÷2-mesh.nx:-1]\n    ky = 2π/(mesh.ymax-mesh.ymin)*[0:mesh.ny÷2-1;mesh.ny÷2-mesh.ny:-1]\n    \n    f  = zeros(ComplexF64,(mesh.nx,mesh.ny))\n    f .= compute_exact_solution(0.0, mesh)\n    f̂  = similar(f)\n\n    exky = exp.( 1im*tan(dt/2) .* mesh.x  .* ky')\n    ekxy = exp.(-1im*sin(dt)   .* mesh.y' .* kx )\n        \n    Px = plan_fft(f, 1)\n    Py = plan_fft(f, 2)\n        \n    for n = 1:nsteps\n        \n        f̂ .= Py * f\n        f̂ .= f̂  .* exky\n        f .= Py \\ f̂\n        \n        f̂ .= Px * f\n        f̂ .= f̂  .* ekxy \n        f .= Px \\ f̂\n        \n        f̂ .= Py * f\n        f̂ .= f̂  .* exky\n        f .= Py \\ f̂\n        \n    end\n\n    real(f)\nend\n\nwith_fft_plans (generic function with 1 method)\n\n\n\nnsteps, final_time = 1000, 200\nsol1 = with_fft_plans(final_time, nsteps, mesh)\nsol2 = compute_exact_solution(final_time, mesh)\nprintln( \" error = \", compute_error(sol1, sol2))\n@btime with_fft_plans(final_time, nsteps, mesh);\n\n error = 1.8686623861233415e-13\n  2.197 s (18030 allocations: 2.93 GiB)"
  },
  {
    "objectID": "diffeq/rotation-with-fft.html#inplace-computation-and-fft-plans",
    "href": "diffeq/rotation-with-fft.html#inplace-computation-and-fft-plans",
    "title": "Rotation using FFT",
    "section": "Inplace computation and fft plans",
    "text": "Inplace computation and fft plans\nTo apply fft plan to an array A, we use a preallocated output array Â by calling mul!(Â, plan, A). The input array A must be a complex floating-point array like the output Â. The inverse-transform is computed inplace by applying inv(P) with ldiv!(A, P, Â).\n\nfunction with_fft_plans_inplace(final_time, nsteps, mesh::TwoDMesh)\n\n    dt = final_time/nsteps\n\n    kx = 2π/(mesh.xmax-mesh.xmin) .* fftfreq(mesh.nx, mesh.nx)\n    ky = 2π/(mesh.ymax-mesh.ymin) .* fftfreq(mesh.ny, mesh.ny)\n    \n    f  = zeros(ComplexF64,(mesh.nx,mesh.ny))\n    f .= compute_exact_solution(0.0, mesh)\n    f̂  = similar(f)\n\n    exky = exp.( 1im*tan(dt/2) .* mesh.x  .* ky')\n    ekxy = exp.(-1im*sin(dt)   .* mesh.y' .* kx )\n\n    Px = plan_fft(f, 1)    \n    Py = plan_fft(f, 2)\n        \n    for n = 1:nsteps\n        \n        mul!(f̂, Py, f)\n        f̂ .= f̂ .* exky\n        ldiv!(f, Py, f̂)\n        \n        mul!(f̂, Px, f)\n        f̂ .= f̂ .* ekxy \n        ldiv!(f, Px, f̂)\n        \n        mul!(f̂, Py, f)\n        f̂ .= f̂ .* exky\n        ldiv!(f, Py, f̂)\n        \n    end\n\n    real(f)\nend\n\nwith_fft_plans_inplace (generic function with 1 method)\n\n\n\nnsteps, final_time = 1000, 200\nsol1 = with_fft_plans_inplace(final_time, nsteps, mesh)\nsol2 = compute_exact_solution(final_time, mesh)\nprintln( \" error = \", compute_error(sol1, sol2 ))\n@btime with_fft_plans_inplace(final_time, nsteps, mesh);\n\n error = 1.8686623861233415e-13\n  1.662 s (6026 allocations: 3.82 MiB)"
  },
  {
    "objectID": "diffeq/rotation-with-fft.html#explicit-transpose-of-f",
    "href": "diffeq/rotation-with-fft.html#explicit-transpose-of-f",
    "title": "Rotation using FFT",
    "section": "Explicit transpose of f",
    "text": "Explicit transpose of f\n\nMultidimensional arrays in Julia are stored in column-major order.\nFFTs along y are slower than FFTs along x\nWe can speed-up the computation by allocating the transposed f and transpose f for each advection along y.\n\n\nfunction with_fft_transposed(final_time, nsteps, mesh::TwoDMesh)\n\n    dt = final_time/nsteps\n\n    kx = 2π/(mesh.xmax-mesh.xmin) .* fftfreq(mesh.nx, mesh.nx)\n    ky = 2π/(mesh.ymax-mesh.ymin) .* fftfreq(mesh.ny, mesh.ny)\n    \n    f  = zeros(ComplexF64,(mesh.nx,mesh.ny))\n    f̂  = similar(f)\n    fᵗ = zeros(ComplexF64,(mesh.ny,mesh.nx))\n    f̂ᵗ = similar(fᵗ)\n\n    exky = exp.( 1im*tan(dt/2) .* mesh.x' .* ky )\n    ekxy = exp.(-1im*sin(dt)   .* mesh.y' .* kx )\n    \n    FFTW.set_num_threads(4)\n    Px = plan_fft(f,  1, flags=FFTW.PATIENT)    \n    Py = plan_fft(fᵗ, 1, flags=FFTW.PATIENT)\n    \n    f .= compute_exact_solution(0.0, mesh)\n    \n    for n = 1:nsteps\n\n        transpose!(fᵗ,f)\n        mul!(f̂ᵗ, Py, fᵗ)\n        f̂ᵗ .= f̂ᵗ .* exky\n        ldiv!(fᵗ, Py, f̂ᵗ)\n        transpose!(f,fᵗ)\n        \n        mul!(f̂, Px, f)\n        f̂ .= f̂ .* ekxy \n        ldiv!(f, Px, f̂)\n        \n        transpose!(fᵗ,f)\n        mul!(f̂ᵗ, Py, fᵗ)\n        f̂ᵗ .= f̂ᵗ .* exky\n        ldiv!(fᵗ, Py, f̂ᵗ)\n        transpose!(f,fᵗ)\n\n    end\n\n    real(f)\n\nend\n\nwith_fft_transposed (generic function with 1 method)\n\n\n\nnsteps, final_time = 1000, 200\nsol1 = with_fft_transposed(final_time, nsteps, mesh)\nsol2 = compute_exact_solution(final_time, mesh)\nprintln( \" error = \", compute_error(sol1, sol2))\n@btime with_fft_transposed(final_time, nsteps, mesh);\n\n error = 1.8528178494398663e-13\n  655.074 ms (6038 allocations: 6.82 MiB)\n\n\n\nfinal_time, nsteps = 400π, 1000\nmesh = TwoDMesh(-π, π, 512, -π, π, 256)\n\nTwoDMesh(512, 256, -3.141592653589793, 3.141592653589793, -3.141592653589793, 3.141592653589793, 0.01227184630308513, 0.02454369260617026, [-3.141592653589793, -3.129320807286708, -3.1170489609836225, -3.104777114680538, -3.0925052683774528, -3.0802334220743677, -3.067961575771282, -3.055689729468197, -3.0434178831651124, -3.0311460368620273  …  3.018874190558941, 3.031146036862027, 3.0434178831651115, 3.0556897294681966, 3.0679615757712817, 3.0802334220743672, 3.092505268377452, 3.104777114680537, 3.117048960983622, 3.1293208072867076], [-3.141592653589793, -3.117048960983623, -3.0925052683774528, -3.0679615757712826, -3.0434178831651124, -3.0188741905589414, -2.994330497952771, -2.969786805346601, -2.945243112740431, -2.9206994201342606  …  2.8961557275280905, 2.9206994201342606, 2.945243112740431, 2.969786805346601, 2.994330497952771, 3.0188741905589414, 3.0434178831651124, 3.0679615757712826, 3.0925052683774528, 3.117048960983623])\n\n\n\ninplace_bench = @benchmark inplace(final_time, nsteps, mesh)\nvectorized_bench = @benchmark vectorized(final_time, nsteps, mesh)\nwith_fft_plans_bench = @benchmark with_fft_plans(final_time, nsteps, mesh)\nwith_fft_plans_inplace_bench = @benchmark with_fft_plans_inplace(final_time, nsteps, mesh)\nwith_fft_transposed_bench = @benchmark with_fft_transposed(final_time, nsteps, mesh)\n\n\nBenchmarkTools.Trial: 3 samples with 1 evaluation.\n Range (min … max):  2.448 s …   2.490 s  ┊ GC (min … max): 0.00% … 0.04%\n Time  (median):     2.471 s              ┊ GC (median):    0.00%\n Time  (mean ± σ):   2.470 s ± 20.937 ms  ┊ GC (mean ± σ):  0.01% ± 0.02%\n  █                              █                        █  \n  █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█ ▁\n  2.45 s         Histogram: frequency by time        2.49 s &lt;\n Memory estimate: 26.32 MiB, allocs estimate: 6038.\n\n\n\n\nd = Dict() \nd[\"vectorized\"] = minimum(vectorized_bench.times) / 1e6\nd[\"inplace\"] = minimum(inplace_bench.times) / 1e6\nd[\"with_fft_plans\"] = minimum(with_fft_plans_bench.times) / 1e6\nd[\"with_fft_plans_inplace\"] = minimum(with_fft_plans_inplace_bench.times) / 1e6\nd[\"with_fft_transposed\"] = minimum(with_fft_transposed_bench.times) / 1e6;\n\n\nfor (key, value) in sort(collect(d), by=last)\n    println(rpad(key, 25, \".\"), lpad(round(value, digits=1), 6, \".\"))\nend\n\nwith_fft_transposed......2448.4\nwith_fft_plans_inplace...4343.3\ninplace..................4615.8\nwith_fft_plans...........6010.0\nvectorized...............6167.2"
  },
  {
    "objectID": "diffeq/rotation-with-fft.html#conclusion",
    "href": "diffeq/rotation-with-fft.html#conclusion",
    "title": "Rotation using FFT",
    "section": "Conclusion",
    "text": "Conclusion\n\nUsing pre-allocations of memory and inplace computation is very important\nTry to always do computation on data contiguous in memory\nUse plans for fft"
  },
  {
    "objectID": "index.html#why-julia",
    "href": "index.html#why-julia",
    "title": "Maths with Julia",
    "section": "Why Julia?",
    "text": "Why Julia?\n\nIncrease the programmer productivity.\nPython is a very nice language to code a prototype but i had to use Cython to make it faster. And had to code in Fortran if the code had to be deployed on HPC cluster\nHigh-level languages like python and R let one explore and experiment rapidly, but can run slow.\nLow-level languages like Fortran/C++ tend to take longer to develop, but run fast.\nThis is sometimes called the “two language problem” and is something the Julia developers set out to eliminate.\nMy code runs much faster than Python, and typically similar to Fortran.\n\nJulia provides a “best of both worlds” experience for programmers who need to develop novel algorithms and bring them into production environments with minimal effort."
  },
  {
    "objectID": "index.html#julia-features",
    "href": "index.html#julia-features",
    "title": "Maths with Julia",
    "section": "Julia features",
    "text": "Julia features\n\nHigh-level language for numerical computing.\nBorn in 2009 and version 1.0 was released in August 2018.\nDynamically-typed with optional types, feels like a scripting language, and has good support for interactive use.\nEasy to learn for people that comes from R and Python.\nDesigned from the beginning to be fast as Fortran and C\nJulia programs compile to efficient native code via LLVM.\nDesigned for parallelism, and provides built-in primitives for parallel computing\ncan call C and Fortran libraries natively\ncan call Python libraries via PyCall package\ncan call R functions via RCall package"
  },
  {
    "objectID": "index.html#julia-is-a-language-made-for-science.",
    "href": "index.html#julia-is-a-language-made-for-science.",
    "title": "Maths with Julia",
    "section": "Julia is a language made for Science.",
    "text": "Julia is a language made for Science.\n\nMathematics\n\nJuliaDiff – Differentiation tools\nJuliaDiffEq – Differential equation solving and analysis\nJuliaGeometry – Computational Geometry\nJuliaGraphs – Graph Theory and Implementation\nJuliaIntervals - Rigorous numerics with interval arithmetic & applications\nJuliaMath – Mathematics made easy in Julia\nJuliaOpt – Optimization (Gitter)\nJuliaPolyhedra – Polyhedral computation\nJuliaSparse – Sparse matrix solvers\n\n\n\nData Science\n\nJuliaML – Machine Learning\nJuliaStats – Statistics\nJuliaImages – Image Processing\nJuliaText – Natural Language Processing (NLP), Computational Linguistics and (textual) Information Retrieval\nJuliaDatabases – Various database drivers for Julia\nJuliaData – Data manipulation, storage, and I/O in Julia"
  },
  {
    "objectID": "performance/access-arrays-in-memory-order.html",
    "href": "performance/access-arrays-in-memory-order.html",
    "title": "Memory order",
    "section": "",
    "text": "“N-dimensional arrays are stored in column-major layout. The elements from the first (leftmost) dimension or index are contiguous in memory.”\n\nfunction compute_dist!(x, dist)\n    for i=eachindex(x)\n        for j=eachindex(x)\n            dist[i, j] = abs(x[i] - x[j])\n        end\n    end\nend\n\nN = 10_000\nx = rand(Float64, N)\ndist = Array{Float64}(undef, (N, N))\n\ncompute_dist!(x, dist)\n@time compute_dist!(x, dist)\n\n  0.152125 seconds\n\n\n\n\nfunction compute_dist!(x, dist)\n    for j=eachindex(x)\n        for i=eachindex(x)\n            dist[i, j] = abs(x[i] - x[j])\n        end\n    end\nend\n\nN = 10_000\nx = rand(Float64, N)\ndist = Array{Float64}(undef, (N, N))\n\ncompute_dist!(x, dist)\n@time compute_dist!(x, dist)\n\n  0.039691 seconds\n\n\n\n\nusing BenchmarkTools, FFTW\nxmin, xmax, nx = 0, 4π, 1024\nymin, ymax, ny = 0, 4π, 1024\nx = LinRange(xmin, xmax, nx+1)[1:end-1]\ny = LinRange(ymin, ymax, ny+1)[1:end-1]\n\nfunction df_dy!( f )\n    ky  = 2π ./ (ymax-ymin) .* fftfreq(ny, ny)\n    exky = exp.( 1im .* ky' .* x)\n    f .= real(ifft(exky .* fft(f, 2), 2))\nend\n\nf1 = sin.(x) .* cos.(y') \ndf_dy!( f1 );\n\n\n\nfunction df_dy_transposed!( f )\n    ft = transpose(f)\n    ky  = 2π ./ (ymax-ymin) .* fftfreq(ny, ny)\n    exky = exp.( 1im .* ky .* x')\n    f .= transpose(real(ifft(exky .* fft(ft, 1), 1)))\nend\nf2 = sin.(x) .* cos.(y') \ndf_dy_transposed!( f2 );\n\n\n\nisequal(f1, f2)\n\ntrue\n\n\n\nf = sin.(x) .* cos.(y')\n@btime df_dy!($f);\nf = sin.(x) .* cos.(y')\n@btime df_dy_transposed!($f);\n\n  77.632 ms (36 allocations: 88.01 MiB)\n  35.405 ms (37 allocations: 88.01 MiB)"
  },
  {
    "objectID": "performance/good-practices-for-io.html",
    "href": "performance/good-practices-for-io.html",
    "title": "Good practices for I/O",
    "section": "",
    "text": "When writing data to a file (or other I/O device), forming extra intermediate strings is a source of overhead. Instead of:\nprintln(file, \"$a $b\")\nuse:\nprintln(file, a, \" \", b)"
  },
  {
    "objectID": "performance/good-practices-for-io.html#avoid-string-interpolation-for-io",
    "href": "performance/good-practices-for-io.html#avoid-string-interpolation-for-io",
    "title": "Good practices for I/O",
    "section": "",
    "text": "When writing data to a file (or other I/O device), forming extra intermediate strings is a source of overhead. Instead of:\nprintln(file, \"$a $b\")\nuse:\nprintln(file, a, \" \", b)"
  },
  {
    "objectID": "performance/performance-annotations.html",
    "href": "performance/performance-annotations.html",
    "title": "Performance annotations",
    "section": "",
    "text": "function new_sum(myvec::Vector{Int})\n    s = zero(eltype(myvec))\n    for i = eachindex(myvec)\n        s += myvec[i]\n    end\n    return s\nend\n\nfunction new_sum_inbounds(myvec::Vector{Int})\n    s = zero(eltype(myvec))\n    @inbounds for i = eachindex(myvec)\n        s += myvec[i]\n    end\n    return s\nend\n\nnew_sum_inbounds (generic function with 1 method)\n\n\n\nusing BenchmarkTools\n\nmyvec = collect(1:1000000)\n@btime new_sum($myvec)\n@btime new_sum_inbounds($myvec)\n\n  89.206 μs (0 allocations: 0 bytes)\n  96.339 μs (0 allocations: 0 bytes)\n\n\n500000500000\n\n\n\n\n\n\n@noinline function inner(x, y)\n    s = zero(eltype(x))\n    for i = eachindex(x, y)\n        @inbounds s += x[i]*y[i]\n    end\n    return s\nend;\n\n\n\n@noinline function innersimd(x, y)\n    s = zero(eltype(x))\n    @simd for i = eachindex(x, y)\n        @inbounds s += x[i] * y[i]\n    end\n    return s\nend;\n\n\n\n\n\nfunction timeit(n, reps)\n    x = rand(Float32, n)\n    y = rand(Float32, n)\n    s = zero(Float64)\n    time = @elapsed for j in 1:reps\n        s += inner(x, y)\n    end\n    println(\"GFlop/sec        = \", 2n*reps / time*1E-9)\n    time = @elapsed for j in 1:reps\n        s += innersimd(x, y)\n    end\n    println(\"GFlop/sec (SIMD) = \", 2n*reps / time*1E-9)\nend\ntimeit(10, 10)\ntimeit(1000, 1000)\n\nGFlop/sec        = 0.7692307692307693\nGFlop/sec (SIMD) = 0.48661800486618\nGFlop/sec        = 2.2195365829568443\nGFlop/sec (SIMD) = 43.172300651901736\n\n\n\n\nfunction init!(u::Vector)\n    n = length(u)\n    dx = 1.0 / (n-1)\n    @fastmath @inbounds @simd for i in eachindex(u) \n        u[i] = sin(2pi*dx*i)\n    end\nend\n\nfunction deriv!(u::Vector, du)\n    n = length(u)\n    dx = 1.0 / (n-1)\n    @fastmath @inbounds du[1] = (u[2] - u[1]) / dx\n    @fastmath @inbounds @simd for i in 2:n-1\n        du[i] = (u[i+1] - u[i-1]) / (2*dx)\n    end\n    @fastmath @inbounds du[n] = (u[n] - u[n-1]) / dx\nend\n\nderiv! (generic function with 1 method)\n\n\n\n\nfunction mynorm(u::Vector)\n    T = eltype(u)\n    s = zero(T)\n    @fastmath @inbounds @simd for i in eachindex(u)\n        s += u[i]^2\n    end\n    @fastmath @inbounds return sqrt(s)\nend\n\nmynorm (generic function with 1 method)\n\n\n\n\nfunction main(n)\n    u = Vector{Float64}(undef, n)\n    init!(u)\n    du = similar(u)\n\n    deriv!(u, du)\n    nu = mynorm(du)\n\n    @time for i in 1:10^6\n        deriv!(u, du)\n        nu = mynorm(du)\n    end\n\n    println(\" nu = $nu \")\nend\n\nmain(10)\n@time main(2000)\n\n  0.023394 seconds\n nu = 13.187330309540112 \n  0.457951 seconds\n nu = 198.74110382490193 \n  0.458161 seconds (187 allocations: 44.430 KiB)\n\n\n\n\nrun(`julia --math-mode=ieee performance/wave.jl`)\n\n  0.032788 seconds\n nu = 13.187330309540112 \n  0.872121 seconds\n nu = 198.74110382490198 \n  0.872228 seconds (26 allocations: 33.352 KiB)\n\n\n\nProcess(`julia --math-mode=ieee performance/wave.jl`, ProcessExited(0))"
  },
  {
    "objectID": "performance/vectorized-operations.html",
    "href": "performance/vectorized-operations.html",
    "title": "Vectorized operations",
    "section": "",
    "text": "f(x) = 3x.^2 + 4x + 7x.^3;\n\nfdot(x) = @. 3x^2 + 4x + 7x^3; # = 3 .* x.^2 .+ 4 .* x .+ 7 .* x.^3\nBoth f and fdot compute the same thing.\nx = rand(10^6);\nf(x) # warmup\n@time f(x);\n\n  0.015379 seconds (12 allocations: 45.777 MiB, 38.69% gc time)\nfdot(x) # warmup\n@time fdot(x);\n\n  0.001497 seconds (2 allocations: 7.629 MiB)\nf.(x) # warmup\n@time f.(x);\n\n  0.001535 seconds (4 allocations: 7.629 MiB)\nfdot(x) is faster and allocates less memory, because each * and + operation in f(x) allocates a new temporary array and executes in a separate loop."
  },
  {
    "objectID": "performance/vectorized-operations.html#consider-using-views-for-slices",
    "href": "performance/vectorized-operations.html#consider-using-views-for-slices",
    "title": "Vectorized operations",
    "section": "Consider using views for slices",
    "text": "Consider using views for slices\n\nlet\n\n   N = 50_000_000\n   a = 1.2\n   x = rand(Float64, N)\n   y = rand(Float64, N)\n   \n   nn = 100\n   n_start = 1 + nn\n   n_end = N - nn\n   \n   # timing\n   @time @. y[n_start:n_end] += a * x[n_start:n_end];\n\n   # timing\n   @time @. @views y[n_start:n_end] += a * x[n_start:n_end];\n\n   nothing\n\nend\n\n  0.155716 seconds (4 allocations: 762.936 MiB, 2.51% gc time)\n  0.048488 seconds"
  },
  {
    "objectID": "performance/vectorized-operations.html#copy-irregularly-accessed-data-into-a-contiguous-array-before-operating-on-it",
    "href": "performance/vectorized-operations.html#copy-irregularly-accessed-data-into-a-contiguous-array-before-operating-on-it",
    "title": "Vectorized operations",
    "section": "Copy irregularly-accessed data into a contiguous array before operating on it",
    "text": "Copy irregularly-accessed data into a contiguous array before operating on it\n\nusing Random\n\nx = randn(1_000_000);\n\ninds = shuffle(1:1_000_000)[1:800000];\n\nA = randn(50, 1_000_000);\n\nxtmp = zeros(800_000);\nAtmp = zeros(50, 800_000);\n\n@time sum(view(A, :, inds) * view(x, inds))\n@time sum(view(A, :, inds) * view(x, inds))\n\n  0.276562 seconds (214.16 k allocations: 13.800 MiB, 43.59% compilation time)\n  0.155141 seconds (5 allocations: 624 bytes)\n\n\n-4840.448283101976\n\n\nIrregular access patterns and non-contiguous views can drastically slow down computations on arrays because of non-sequential memory access. Copying the views into plain arrays speeds up the multiplication even with the cost of the copying operation.\n\n\n@time begin\n    copyto!(xtmp, view(x, inds))\n    copyto!(Atmp, view(A, :, inds))\n    sum(Atmp * xtmp)\nend\n\n  0.296795 seconds (209.90 k allocations: 14.377 MiB, 43.33% compilation time)\n\n\n-4840.448283101917\n\n\n\n@time begin\n    copyto!(xtmp, view(x, inds))\n    copyto!(Atmp, view(A, :, inds))\n    sum(Atmp * xtmp)\nend\n\n  0.166564 seconds (5 allocations: 624 bytes)\n\n\n-4840.448283101917"
  },
  {
    "objectID": "performance/write-type-stable-functions.html",
    "href": "performance/write-type-stable-functions.html",
    "title": "Type stability",
    "section": "",
    "text": "function square_plus_one(v::T) where T &lt;:Number\n    g = v * v\n    return g + 1\nend\n\nsquare_plus_one (generic function with 1 method)\nv = rand()\n\n0.5513195579469744\n@code_warntype square_plus_one(v)\n\nMethodInstance for square_plus_one(::Float64)\n  from square_plus_one(v::T) where T&lt;:Number @ Main In[2]:1\nStatic Parameters\n  T = Float64\nArguments\n  #self#::Core.Const(square_plus_one)\n  v::Float64\nLocals\n  g::Float64\nBody::Float64\n1 ─      (g = v * v)\n│   %2 = (g + 1)::Float64\n└──      return %2\nw = 5\n\n5\n@code_warntype square_plus_one(w)\n\nMethodInstance for square_plus_one(::Int64)\n  from square_plus_one(v::T) where T&lt;:Number @ Main In[2]:1\nStatic Parameters\n  T = Int64\nArguments\n  #self#::Core.Const(square_plus_one)\n  v::Int64\nLocals\n  g::Int64\nBody::Int64\n1 ─      (g = v * v)\n│   %2 = (g + 1)::Int64\n└──      return %2\nGreat! In the above two examples, we were able to predict what the output will be. This is because:\nNote that in both calls the return type was different, once Float64 and once Int64. But the function is still type stable.\nfunction zero_or_val(x::Real)\n    if x &gt;= 0\n        return x\n    else\n        return 0\n    end\nend\n@code_warntype zero_or_val(0.2)\n\nMethodInstance for zero_or_val(::Float64)\n  from zero_or_val(x::Real) @ Main In[7]:1\nArguments\n  #self#::Core.Const(zero_or_val)\n  x::Float64\nBody::Union{Float64, Int64}\n1 ─ %1 = (x &gt;= 0)::Bool\n└──      goto #3 if not %1\n2 ─      return x\n3 ─      return 0\nYou can avoid type instable code by using the promote_type function which returns the highest of the two types passed.\nfunction zero_or_val_stable(x::Real)\n    if x &gt;= 0\n        y = x\n    else\n        y = 0\n    end\n    T = promote_type(typeof(x),Int)\n    return T(y)\nend\n@code_warntype zero_or_val_stable(0.2)\n\nMethodInstance for zero_or_val_stable(::Float64)\n  from zero_or_val_stable(x::Real) @ Main In[8]:1\nArguments\n  #self#::Core.Const(zero_or_val_stable)\n  x::Float64\nLocals\n  T::Type{Float64}\n  y::Union{Float64, Int64}\nBody::Float64\n1 ─       Core.NewvarNode(:(T))\n│         Core.NewvarNode(:(y))\n│   %3  = (x &gt;= 0)::Bool\n└──       goto #3 if not %3\n2 ─       (y = x)\n└──       goto #4\n3 ─       (y = 0)\n4 ┄ %8  = Main.typeof(x)::Core.Const(Float64)\n│         (T = Main.promote_type(%8, Main.Int))\n│   %10 = (T::Core.Const(Float64))(y)::Float64\n└──       return %10"
  },
  {
    "objectID": "performance/write-type-stable-functions.html#break-functions-into-multiple-definitions",
    "href": "performance/write-type-stable-functions.html#break-functions-into-multiple-definitions",
    "title": "Type stability",
    "section": "Break functions into multiple definitions",
    "text": "Break functions into multiple definitions\nusing LinearAlgebra\n\nfunction mynorm(A)\n    if isa(A, Vector)\n        return sqrt(real(dot(A,A)))\n    elseif isa(A, Matrix)\n        return maximum(svdvals(A))\n    else\n        error(\"mynorm: invalid argument\")\n    end\nend\nThis can be written more concisely and efficiently as:\nnorm(x::Vector) = sqrt(real(dot(x, x)))\n\nnorm(A::Matrix) = maximum(svdvals(A))"
  },
  {
    "objectID": "performance/write-type-stable-functions.html#avoid-changing-the-type-of-a-variable",
    "href": "performance/write-type-stable-functions.html#avoid-changing-the-type-of-a-variable",
    "title": "Type stability",
    "section": "Avoid changing the type of a variable",
    "text": "Avoid changing the type of a variable\nLet us say we want to play the following game, I give you a vector of numbers. And you want to accumulate the sum as follows. For each number in the vector, you toss a coin (rand()), if it is heads (&gt;=0.5), you add 1. Otherwise, you add the number itself.\n\nfunction flipcoin_then_add(v::Vector{T}) where T &lt;: Real\n    s = 0\n    for vi in v\n        r = rand()\n        if r &gt;=0.5\n            s += 1\n        else\n            s += vi\n        end\n    end\nend\n\nflipcoin_then_add (generic function with 1 method)\n\n\n\n\nfunction flipcoin_then_add_typed(v::Vector{T}) where T &lt;: Real\n    s = zero(T)\n    for vi in v\n        r = rand()\n        if r &gt;=0.5\n            s += one(T)\n        else\n            s += vi\n        end\n    end\nend\n\nflipcoin_then_add_typed (generic function with 1 method)\n\n\n\n\nusing BenchmarkTools\n\nmyvec = rand(1000)\n@show flipcoin_then_add(myvec) == flipcoin_then_add_typed(myvec)\n\nflipcoin_then_add(myvec) == flipcoin_then_add_typed(myvec) = true\n\n\ntrue\n\n\n\n@btime flipcoin_then_add(rand(1000))\n@btime flipcoin_then_add_typed(rand(1000))\n\n  7.181 μs (1 allocation: 7.94 KiB)\n  1.683 μs (1 allocation: 7.94 KiB)"
  }
]